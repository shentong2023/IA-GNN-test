nohup: ignoring input
Namespace(batch_size=100, dataset='diginetica', emb_size=100, epoch=30, epsilon=0.85, evaluate_k=[10, 20], l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, patience=10, temp=0.1)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-03-22 10:54:29.649724
	 train_loss : 47107.484
this_epoch----
recall@10:0.2657	 mrr@10:0.1091
recall@20:0.3740	 mrr@20:0.1166
best_result----
recall@10:0.2657	 mrr@10:0.1091	 epoch:0,0
recall@20:0.3740	 mrr@20:0.1166	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-03-22 10:55:21.562060
	 train_loss : 38529.648
this_epoch----
recall@10:0.2905	 mrr@10:0.1210
recall@20:0.4073	 mrr@20:0.1291
best_result----
recall@10:0.2905	 mrr@10:0.1210	 epoch:1,1
recall@20:0.4073	 mrr@20:0.1291	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-03-22 10:56:09.949235
	 train_loss : 35853.793
this_epoch----
recall@10:0.3010	 mrr@10:0.1271
recall@20:0.4178	 mrr@20:0.1351
best_result----
recall@10:0.3010	 mrr@10:0.1271	 epoch:2,2
recall@20:0.4178	 mrr@20:0.1351	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-03-22 10:56:59.077089
	 train_loss : 34555.508
this_epoch----
recall@10:0.3069	 mrr@10:0.1312
recall@20:0.4238	 mrr@20:0.1393
best_result----
recall@10:0.3069	 mrr@10:0.1312	 epoch:3,3
recall@20:0.4238	 mrr@20:0.1393	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-03-22 10:57:45.846502
	 train_loss : 33795.441
this_epoch----
recall@10:0.3067	 mrr@10:0.1320
recall@20:0.4265	 mrr@20:0.1402
best_result----
recall@10:0.3069	 mrr@10:0.1320	 epoch:3,4
recall@20:0.4265	 mrr@20:0.1402	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-03-22 10:58:36.070266
	 train_loss : 33285.430
this_epoch----
recall@10:0.3100	 mrr@10:0.1334
recall@20:0.4317	 mrr@20:0.1418
best_result----
recall@10:0.3100	 mrr@10:0.1334	 epoch:5,5
recall@20:0.4317	 mrr@20:0.1418	 epoch:5,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-03-22 10:59:26.286439
	 train_loss : 32923.711
this_epoch----
recall@10:0.3135	 mrr@10:0.1350
recall@20:0.4335	 mrr@20:0.1433
best_result----
recall@10:0.3135	 mrr@10:0.1350	 epoch:6,6
recall@20:0.4335	 mrr@20:0.1433	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-03-22 11:00:14.441629
	 train_loss : 32649.461
this_epoch----
recall@10:0.3171	 mrr@10:0.1355
recall@20:0.4366	 mrr@20:0.1437
best_result----
recall@10:0.3171	 mrr@10:0.1355	 epoch:7,7
recall@20:0.4366	 mrr@20:0.1437	 epoch:7,7
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-03-22 11:01:05.268465
	 train_loss : 32397.570
this_epoch----
recall@10:0.3144	 mrr@10:0.1349
recall@20:0.4339	 mrr@20:0.1431
best_result----
recall@10:0.3171	 mrr@10:0.1355	 epoch:7,7
recall@20:0.4366	 mrr@20:0.1437	 epoch:7,7
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-03-22 11:01:55.584456
	 train_loss : 32190.164
this_epoch----
recall@10:0.3152	 mrr@10:0.1358
recall@20:0.4376	 mrr@20:0.1443
best_result----
recall@10:0.3171	 mrr@10:0.1358	 epoch:7,9
recall@20:0.4376	 mrr@20:0.1443	 epoch:9,9
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-03-22 11:02:50.220888
	 train_loss : 30576.424
this_epoch----
recall@10:0.3297	 mrr@10:0.1424
recall@20:0.4483	 mrr@20:0.1507
best_result----
recall@10:0.3297	 mrr@10:0.1424	 epoch:10,10
recall@20:0.4483	 mrr@20:0.1507	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-03-22 11:03:38.288280
	 train_loss : 30318.922
this_epoch----
recall@10:0.3317	 mrr@10:0.1431
recall@20:0.4507	 mrr@20:0.1514
best_result----
recall@10:0.3317	 mrr@10:0.1431	 epoch:11,11
recall@20:0.4507	 mrr@20:0.1514	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-03-22 11:04:34.428213
	 train_loss : 30234.697
this_epoch----
recall@10:0.3318	 mrr@10:0.1436
recall@20:0.4509	 mrr@20:0.1518
best_result----
recall@10:0.3318	 mrr@10:0.1436	 epoch:12,12
recall@20:0.4509	 mrr@20:0.1518	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-03-22 11:05:23.747734
	 train_loss : 30185.914
this_epoch----
recall@10:0.3320	 mrr@10:0.1436
recall@20:0.4526	 mrr@20:0.1520
best_result----
recall@10:0.3320	 mrr@10:0.1436	 epoch:13,13
recall@20:0.4526	 mrr@20:0.1520	 epoch:13,13
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-03-22 11:06:17.393565
	 train_loss : 30148.191
this_epoch----
recall@10:0.3326	 mrr@10:0.1439
recall@20:0.4529	 mrr@20:0.1522
best_result----
recall@10:0.3326	 mrr@10:0.1439	 epoch:14,14
recall@20:0.4529	 mrr@20:0.1522	 epoch:14,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-03-22 11:07:08.753653
	 train_loss : 30121.012
this_epoch----
recall@10:0.3323	 mrr@10:0.1441
recall@20:0.4530	 mrr@20:0.1524
best_result----
recall@10:0.3326	 mrr@10:0.1441	 epoch:14,15
recall@20:0.4530	 mrr@20:0.1524	 epoch:15,15
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-03-22 11:08:02.451508
	 train_loss : 30092.627
this_epoch----
recall@10:0.3319	 mrr@10:0.1441
recall@20:0.4539	 mrr@20:0.1525
best_result----
recall@10:0.3326	 mrr@10:0.1441	 epoch:14,15
recall@20:0.4539	 mrr@20:0.1525	 epoch:16,16
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-03-22 11:08:56.359352
	 train_loss : 30067.479
this_epoch----
recall@10:0.3325	 mrr@10:0.1443
recall@20:0.4539	 mrr@20:0.1527
best_result----
recall@10:0.3326	 mrr@10:0.1443	 epoch:14,17
recall@20:0.4539	 mrr@20:0.1527	 epoch:16,17
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-03-22 11:09:48.876261
	 train_loss : 30046.521
this_epoch----
recall@10:0.3338	 mrr@10:0.1445
recall@20:0.4541	 mrr@20:0.1528
best_result----
recall@10:0.3338	 mrr@10:0.1445	 epoch:18,18
recall@20:0.4541	 mrr@20:0.1528	 epoch:18,18
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-03-22 11:10:43.001438
	 train_loss : 30023.627
this_epoch----
recall@10:0.3329	 mrr@10:0.1443
recall@20:0.4540	 mrr@20:0.1527
best_result----
recall@10:0.3338	 mrr@10:0.1445	 epoch:18,18
recall@20:0.4541	 mrr@20:0.1528	 epoch:18,18
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-03-22 11:11:31.451281
	 train_loss : 29779.422
this_epoch----
recall@10:0.3331	 mrr@10:0.1445
recall@20:0.4541	 mrr@20:0.1529
best_result----
recall@10:0.3338	 mrr@10:0.1445	 epoch:18,18
recall@20:0.4541	 mrr@20:0.1529	 epoch:18,20
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-03-22 11:12:25.090507
	 train_loss : 29770.045
this_epoch----
recall@10:0.3331	 mrr@10:0.1446
recall@20:0.4540	 mrr@20:0.1530
best_result----
recall@10:0.3338	 mrr@10:0.1446	 epoch:18,21
recall@20:0.4541	 mrr@20:0.1530	 epoch:18,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-03-22 11:13:12.776229
	 train_loss : 29764.357
this_epoch----
recall@10:0.3332	 mrr@10:0.1447
recall@20:0.4542	 mrr@20:0.1531
best_result----
recall@10:0.3338	 mrr@10:0.1447	 epoch:18,22
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-03-22 11:14:02.693695
	 train_loss : 29760.539
this_epoch----
recall@10:0.3334	 mrr@10:0.1448
recall@20:0.4538	 mrr@20:0.1531
best_result----
recall@10:0.3338	 mrr@10:0.1448	 epoch:18,23
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,23
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-03-22 11:14:45.939843
	 train_loss : 29756.541
this_epoch----
recall@10:0.3335	 mrr@10:0.1447
recall@20:0.4539	 mrr@20:0.1531
best_result----
recall@10:0.3338	 mrr@10:0.1448	 epoch:18,23
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,23
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-03-22 11:15:31.896310
	 train_loss : 29753.773
this_epoch----
recall@10:0.3336	 mrr@10:0.1447
recall@20:0.4540	 mrr@20:0.1530
best_result----
recall@10:0.3338	 mrr@10:0.1448	 epoch:18,23
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,23
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-03-22 11:16:15.623474
	 train_loss : 29751.873
this_epoch----
recall@10:0.3338	 mrr@10:0.1446
recall@20:0.4540	 mrr@20:0.1529
best_result----
recall@10:0.3338	 mrr@10:0.1448	 epoch:18,23
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,23
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-03-22 11:16:58.430728
	 train_loss : 29750.119
this_epoch----
recall@10:0.3338	 mrr@10:0.1446
recall@20:0.4541	 mrr@20:0.1529
best_result----
recall@10:0.3338	 mrr@10:0.1448	 epoch:18,23
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,23
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-03-22 11:17:41.257297
	 train_loss : 29748.727
this_epoch----
recall@10:0.3338	 mrr@10:0.1446
recall@20:0.4540	 mrr@20:0.1530
best_result----
recall@10:0.3338	 mrr@10:0.1448	 epoch:18,23
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,23
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-03-22 11:18:25.269927
	 train_loss : 29747.152
this_epoch----
recall@10:0.3338	 mrr@10:0.1445
recall@20:0.4539	 mrr@20:0.1528
best_result----
recall@10:0.3338	 mrr@10:0.1448	 epoch:18,23
recall@20:0.4542	 mrr@20:0.1531	 epoch:22,23
Done
