nohup: ignoring input
Namespace(dataset='diginetica', emb_size=100, batch_size=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, temp=0.1, evaluate_k=[10, 20], epsilon=0.85, epoch=30, patience=10)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-04-28 09:31:26.392738
	 train_loss : 37238.996
this_epoch----
recall@10:0.3122	 mrr@10:0.1302
recall@20:0.4362	 mrr@20:0.1388
best_result----
recall@10:0.3122	 mrr@10:0.1302	 epoch:0,0
recall@20:0.4362	 mrr@20:0.1388	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-04-28 09:37:35.903565
	 train_loss : 28125.693
this_epoch----
recall@10:0.3239	 mrr@10:0.1358
recall@20:0.4528	 mrr@20:0.1447
best_result----
recall@10:0.3239	 mrr@10:0.1358	 epoch:1,1
recall@20:0.4528	 mrr@20:0.1447	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-04-28 09:43:34.591174
	 train_loss : 26879.420
this_epoch----
recall@10:0.3336	 mrr@10:0.1405
recall@20:0.4626	 mrr@20:0.1494
best_result----
recall@10:0.3336	 mrr@10:0.1405	 epoch:2,2
recall@20:0.4626	 mrr@20:0.1494	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-04-28 09:50:15.369721
	 train_loss : 26342.648
this_epoch----
recall@10:0.3361	 mrr@10:0.1411
recall@20:0.4642	 mrr@20:0.1499
best_result----
recall@10:0.3361	 mrr@10:0.1411	 epoch:3,3
recall@20:0.4642	 mrr@20:0.1499	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-04-28 09:56:14.465287
	 train_loss : 26027.945
this_epoch----
recall@10:0.3381	 mrr@10:0.1424
recall@20:0.4665	 mrr@20:0.1513
best_result----
recall@10:0.3381	 mrr@10:0.1424	 epoch:4,4
recall@20:0.4665	 mrr@20:0.1513	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-04-28 10:02:18.715699
	 train_loss : 25822.678
this_epoch----
recall@10:0.3350	 mrr@10:0.1410
recall@20:0.4660	 mrr@20:0.1500
best_result----
recall@10:0.3381	 mrr@10:0.1424	 epoch:4,4
recall@20:0.4665	 mrr@20:0.1513	 epoch:4,4
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-04-28 10:08:42.277347
	 train_loss : 25684.180
this_epoch----
recall@10:0.3372	 mrr@10:0.1427
recall@20:0.4675	 mrr@20:0.1517
best_result----
recall@10:0.3381	 mrr@10:0.1427	 epoch:4,6
recall@20:0.4675	 mrr@20:0.1517	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-04-28 10:14:51.272571
	 train_loss : 25585.525
this_epoch----
recall@10:0.3406	 mrr@10:0.1438
recall@20:0.4686	 mrr@20:0.1526
best_result----
recall@10:0.3406	 mrr@10:0.1438	 epoch:7,7
recall@20:0.4686	 mrr@20:0.1526	 epoch:7,7
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-04-28 10:20:58.235525
	 train_loss : 25515.693
this_epoch----
recall@10:0.3391	 mrr@10:0.1439
recall@20:0.4652	 mrr@20:0.1526
best_result----
recall@10:0.3406	 mrr@10:0.1439	 epoch:7,8
recall@20:0.4686	 mrr@20:0.1526	 epoch:7,8
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-04-28 10:26:54.389070
	 train_loss : 25462.764
this_epoch----
recall@10:0.3414	 mrr@10:0.1438
recall@20:0.4701	 mrr@20:0.1526
best_result----
recall@10:0.3414	 mrr@10:0.1439	 epoch:9,8
recall@20:0.4701	 mrr@20:0.1526	 epoch:9,8
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-04-28 10:33:07.649851
	 train_loss : 22838.275
this_epoch----
recall@10:0.3621	 mrr@10:0.1553
recall@20:0.4883	 mrr@20:0.1640
best_result----
recall@10:0.3621	 mrr@10:0.1553	 epoch:10,10
recall@20:0.4883	 mrr@20:0.1640	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-04-28 10:39:06.069933
	 train_loss : 22319.439
this_epoch----
recall@10:0.3630	 mrr@10:0.1565
recall@20:0.4908	 mrr@20:0.1654
best_result----
recall@10:0.3630	 mrr@10:0.1565	 epoch:11,11
recall@20:0.4908	 mrr@20:0.1654	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-04-28 10:45:12.577997
	 train_loss : 22153.857
this_epoch----
recall@10:0.3631	 mrr@10:0.1564
recall@20:0.4925	 mrr@20:0.1654
best_result----
recall@10:0.3631	 mrr@10:0.1565	 epoch:12,11
recall@20:0.4925	 mrr@20:0.1654	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-04-28 10:51:17.222444
	 train_loss : 22065.141
this_epoch----
recall@10:0.3637	 mrr@10:0.1569
recall@20:0.4930	 mrr@20:0.1658
best_result----
recall@10:0.3637	 mrr@10:0.1569	 epoch:13,13
recall@20:0.4930	 mrr@20:0.1658	 epoch:13,13
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-04-28 10:57:13.180957
	 train_loss : 22010.928
this_epoch----
recall@10:0.3641	 mrr@10:0.1570
recall@20:0.4940	 mrr@20:0.1660
best_result----
recall@10:0.3641	 mrr@10:0.1570	 epoch:14,14
recall@20:0.4940	 mrr@20:0.1660	 epoch:14,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-04-28 11:03:25.156656
	 train_loss : 21975.990
this_epoch----
recall@10:0.3649	 mrr@10:0.1573
recall@20:0.4939	 mrr@20:0.1662
best_result----
recall@10:0.3649	 mrr@10:0.1573	 epoch:15,15
recall@20:0.4940	 mrr@20:0.1662	 epoch:14,15
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-04-28 11:09:17.754748
	 train_loss : 21952.303
this_epoch----
recall@10:0.3637	 mrr@10:0.1566
recall@20:0.4944	 mrr@20:0.1657
best_result----
recall@10:0.3649	 mrr@10:0.1573	 epoch:15,15
recall@20:0.4944	 mrr@20:0.1662	 epoch:16,15
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-04-28 11:15:32.167866
	 train_loss : 21934.988
this_epoch----
recall@10:0.3645	 mrr@10:0.1572
recall@20:0.4937	 mrr@20:0.1661
best_result----
recall@10:0.3649	 mrr@10:0.1573	 epoch:15,15
recall@20:0.4944	 mrr@20:0.1662	 epoch:16,15
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-04-28 11:21:34.958063
	 train_loss : 21924.154
this_epoch----
recall@10:0.3639	 mrr@10:0.1571
recall@20:0.4937	 mrr@20:0.1661
best_result----
recall@10:0.3649	 mrr@10:0.1573	 epoch:15,15
recall@20:0.4944	 mrr@20:0.1662	 epoch:16,15
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-04-28 11:27:36.759608
	 train_loss : 21916.441
this_epoch----
recall@10:0.3647	 mrr@10:0.1573
recall@20:0.4938	 mrr@20:0.1662
best_result----
recall@10:0.3649	 mrr@10:0.1573	 epoch:15,15
recall@20:0.4944	 mrr@20:0.1662	 epoch:16,15
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-04-28 11:33:33.121397
	 train_loss : 21381.090
this_epoch----
recall@10:0.3643	 mrr@10:0.1574
recall@20:0.4938	 mrr@20:0.1664
best_result----
recall@10:0.3649	 mrr@10:0.1574	 epoch:15,20
recall@20:0.4944	 mrr@20:0.1664	 epoch:16,20
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-04-28 11:39:29.310192
	 train_loss : 21360.996
this_epoch----
recall@10:0.3649	 mrr@10:0.1578
recall@20:0.4942	 mrr@20:0.1667
best_result----
recall@10:0.3649	 mrr@10:0.1578	 epoch:21,21
recall@20:0.4944	 mrr@20:0.1667	 epoch:16,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-04-28 11:45:30.819889
	 train_loss : 21348.840
this_epoch----
recall@10:0.3653	 mrr@10:0.1579
recall@20:0.4945	 mrr@20:0.1668
best_result----
recall@10:0.3653	 mrr@10:0.1579	 epoch:22,22
recall@20:0.4945	 mrr@20:0.1668	 epoch:22,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-04-28 11:51:26.372021
	 train_loss : 21341.424
this_epoch----
recall@10:0.3653	 mrr@10:0.1577
recall@20:0.4949	 mrr@20:0.1666
best_result----
recall@10:0.3653	 mrr@10:0.1579	 epoch:22,22
recall@20:0.4949	 mrr@20:0.1668	 epoch:23,22
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-04-28 11:57:24.888005
	 train_loss : 21335.762
this_epoch----
recall@10:0.3652	 mrr@10:0.1579
recall@20:0.4949	 mrr@20:0.1669
best_result----
recall@10:0.3653	 mrr@10:0.1579	 epoch:22,24
recall@20:0.4949	 mrr@20:0.1669	 epoch:23,24
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-04-28 12:03:22.491809
	 train_loss : 21331.207
this_epoch----
recall@10:0.3651	 mrr@10:0.1581
recall@20:0.4948	 mrr@20:0.1671
best_result----
recall@10:0.3653	 mrr@10:0.1581	 epoch:22,25
recall@20:0.4949	 mrr@20:0.1671	 epoch:23,25
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-04-28 12:09:21.298052
	 train_loss : 21327.496
this_epoch----
recall@10:0.3653	 mrr@10:0.1581
recall@20:0.4947	 mrr@20:0.1670
best_result----
recall@10:0.3653	 mrr@10:0.1581	 epoch:22,25
recall@20:0.4949	 mrr@20:0.1671	 epoch:23,25
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-04-28 12:15:14.095482
	 train_loss : 21324.506
this_epoch----
recall@10:0.3655	 mrr@10:0.1580
recall@20:0.4947	 mrr@20:0.1670
best_result----
recall@10:0.3655	 mrr@10:0.1581	 epoch:27,25
recall@20:0.4949	 mrr@20:0.1671	 epoch:23,25
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-04-28 12:21:17.229186
	 train_loss : 21321.113
this_epoch----
recall@10:0.3651	 mrr@10:0.1581
recall@20:0.4949	 mrr@20:0.1671
best_result----
recall@10:0.3655	 mrr@10:0.1581	 epoch:27,28
recall@20:0.4949	 mrr@20:0.1671	 epoch:23,28
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-04-28 12:27:10.520259
	 train_loss : 21318.869
this_epoch----
recall@10:0.3651	 mrr@10:0.1581
recall@20:0.4951	 mrr@20:0.1671
best_result----
recall@10:0.3655	 mrr@10:0.1581	 epoch:27,28
recall@20:0.4951	 mrr@20:0.1671	 epoch:29,28
Done
