nohup: ignoring input
Namespace(dataset='diginetica', emb_size=100, batch_size=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, temp=0.1, evaluate_k=[10, 20], epsilon=0.85, epoch=30, patience=10)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-04-28 15:39:02.634806
	 train_loss : 37751.301
this_epoch----
recall@10:0.3129	 mrr@10:0.1314
recall@20:0.4408	 mrr@20:0.1402
best_result----
recall@10:0.3129	 mrr@10:0.1314	 epoch:0,0
recall@20:0.4408	 mrr@20:0.1402	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-04-28 15:43:02.132945
	 train_loss : 28064.113
this_epoch----
recall@10:0.3270	 mrr@10:0.1366
recall@20:0.4575	 mrr@20:0.1456
best_result----
recall@10:0.3270	 mrr@10:0.1366	 epoch:1,1
recall@20:0.4575	 mrr@20:0.1456	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-04-28 15:47:00.953312
	 train_loss : 26875.551
this_epoch----
recall@10:0.3320	 mrr@10:0.1395
recall@20:0.4602	 mrr@20:0.1483
best_result----
recall@10:0.3320	 mrr@10:0.1395	 epoch:2,2
recall@20:0.4602	 mrr@20:0.1483	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-04-28 15:51:04.965475
	 train_loss : 26329.602
this_epoch----
recall@10:0.3354	 mrr@10:0.1411
recall@20:0.4653	 mrr@20:0.1501
best_result----
recall@10:0.3354	 mrr@10:0.1411	 epoch:3,3
recall@20:0.4653	 mrr@20:0.1501	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-04-28 15:55:02.268467
	 train_loss : 26021.127
this_epoch----
recall@10:0.3333	 mrr@10:0.1406
recall@20:0.4637	 mrr@20:0.1496
best_result----
recall@10:0.3354	 mrr@10:0.1411	 epoch:3,3
recall@20:0.4653	 mrr@20:0.1501	 epoch:3,3
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-04-28 15:59:03.779179
	 train_loss : 25823.697
this_epoch----
recall@10:0.3357	 mrr@10:0.1411
recall@20:0.4653	 mrr@20:0.1501
best_result----
recall@10:0.3357	 mrr@10:0.1411	 epoch:5,5
recall@20:0.4653	 mrr@20:0.1501	 epoch:5,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-04-28 16:03:02.032301
	 train_loss : 25681.699
this_epoch----
recall@10:0.3392	 mrr@10:0.1427
recall@20:0.4701	 mrr@20:0.1517
best_result----
recall@10:0.3392	 mrr@10:0.1427	 epoch:6,6
recall@20:0.4701	 mrr@20:0.1517	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-04-28 16:06:53.844666
	 train_loss : 25581.000
this_epoch----
recall@10:0.3385	 mrr@10:0.1424
recall@20:0.4687	 mrr@20:0.1514
best_result----
recall@10:0.3392	 mrr@10:0.1427	 epoch:6,6
recall@20:0.4701	 mrr@20:0.1517	 epoch:6,6
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-04-28 16:10:48.575411
	 train_loss : 25512.352
this_epoch----
recall@10:0.3413	 mrr@10:0.1426
recall@20:0.4706	 mrr@20:0.1515
best_result----
recall@10:0.3413	 mrr@10:0.1427	 epoch:8,6
recall@20:0.4706	 mrr@20:0.1517	 epoch:8,6
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-04-28 16:14:43.192095
	 train_loss : 25453.230
this_epoch----
recall@10:0.3407	 mrr@10:0.1441
recall@20:0.4687	 mrr@20:0.1529
best_result----
recall@10:0.3413	 mrr@10:0.1441	 epoch:8,9
recall@20:0.4706	 mrr@20:0.1529	 epoch:8,9
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-04-28 16:18:38.474362
	 train_loss : 22812.879
this_epoch----
recall@10:0.3615	 mrr@10:0.1547
recall@20:0.4889	 mrr@20:0.1634
best_result----
recall@10:0.3615	 mrr@10:0.1547	 epoch:10,10
recall@20:0.4889	 mrr@20:0.1634	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-04-28 16:22:34.320437
	 train_loss : 22299.484
this_epoch----
recall@10:0.3630	 mrr@10:0.1566
recall@20:0.4914	 mrr@20:0.1655
best_result----
recall@10:0.3630	 mrr@10:0.1566	 epoch:11,11
recall@20:0.4914	 mrr@20:0.1655	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-04-28 16:26:30.579587
	 train_loss : 22141.465
this_epoch----
recall@10:0.3624	 mrr@10:0.1569
recall@20:0.4914	 mrr@20:0.1658
best_result----
recall@10:0.3630	 mrr@10:0.1569	 epoch:11,12
recall@20:0.4914	 mrr@20:0.1658	 epoch:11,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-04-28 16:30:26.644398
	 train_loss : 22058.910
this_epoch----
recall@10:0.3631	 mrr@10:0.1568
recall@20:0.4929	 mrr@20:0.1658
best_result----
recall@10:0.3631	 mrr@10:0.1569	 epoch:13,12
recall@20:0.4929	 mrr@20:0.1658	 epoch:13,12
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-04-28 16:34:27.741341
	 train_loss : 22009.088
this_epoch----
recall@10:0.3631	 mrr@10:0.1571
recall@20:0.4933	 mrr@20:0.1661
best_result----
recall@10:0.3631	 mrr@10:0.1571	 epoch:14,14
recall@20:0.4933	 mrr@20:0.1661	 epoch:14,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-04-28 16:38:22.644206
	 train_loss : 21977.543
this_epoch----
recall@10:0.3634	 mrr@10:0.1569
recall@20:0.4943	 mrr@20:0.1660
best_result----
recall@10:0.3634	 mrr@10:0.1571	 epoch:15,14
recall@20:0.4943	 mrr@20:0.1661	 epoch:15,14
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-04-28 16:42:23.465229
	 train_loss : 21957.752
this_epoch----
recall@10:0.3633	 mrr@10:0.1571
recall@20:0.4936	 mrr@20:0.1661
best_result----
recall@10:0.3634	 mrr@10:0.1571	 epoch:15,16
recall@20:0.4943	 mrr@20:0.1661	 epoch:15,16
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-04-28 16:46:17.774238
	 train_loss : 21943.160
this_epoch----
recall@10:0.3637	 mrr@10:0.1572
recall@20:0.4936	 mrr@20:0.1662
best_result----
recall@10:0.3637	 mrr@10:0.1572	 epoch:17,17
recall@20:0.4943	 mrr@20:0.1662	 epoch:15,17
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-04-28 16:50:09.294488
	 train_loss : 21934.145
this_epoch----
recall@10:0.3646	 mrr@10:0.1578
recall@20:0.4948	 mrr@20:0.1668
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:18,18
recall@20:0.4948	 mrr@20:0.1668	 epoch:18,18
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-04-28 16:54:02.565151
	 train_loss : 21928.445
this_epoch----
recall@10:0.3636	 mrr@10:0.1570
recall@20:0.4946	 mrr@20:0.1661
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:18,18
recall@20:0.4948	 mrr@20:0.1668	 epoch:18,18
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-04-28 16:57:55.121460
	 train_loss : 21394.838
this_epoch----
recall@10:0.3643	 mrr@10:0.1574
recall@20:0.4946	 mrr@20:0.1664
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:18,18
recall@20:0.4948	 mrr@20:0.1668	 epoch:18,18
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-04-28 17:01:53.444423
	 train_loss : 21376.143
this_epoch----
recall@10:0.3644	 mrr@10:0.1576
recall@20:0.4949	 mrr@20:0.1666
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:18,18
recall@20:0.4949	 mrr@20:0.1668	 epoch:21,18
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-04-28 17:05:49.461623
	 train_loss : 21364.980
this_epoch----
recall@10:0.3642	 mrr@10:0.1578
recall@20:0.4946	 mrr@20:0.1668
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:18,22
recall@20:0.4949	 mrr@20:0.1668	 epoch:21,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-04-28 17:09:42.953252
	 train_loss : 21358.439
this_epoch----
recall@10:0.3647	 mrr@10:0.1580
recall@20:0.4944	 mrr@20:0.1670
best_result----
recall@10:0.3647	 mrr@10:0.1580	 epoch:23,23
recall@20:0.4949	 mrr@20:0.1670	 epoch:21,23
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-04-28 17:13:41.884114
	 train_loss : 21353.328
this_epoch----
recall@10:0.3648	 mrr@10:0.1582
recall@20:0.4942	 mrr@20:0.1671
best_result----
recall@10:0.3648	 mrr@10:0.1582	 epoch:24,24
recall@20:0.4949	 mrr@20:0.1671	 epoch:21,24
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-04-28 17:17:38.192021
	 train_loss : 21349.572
this_epoch----
recall@10:0.3649	 mrr@10:0.1581
recall@20:0.4943	 mrr@20:0.1670
best_result----
recall@10:0.3649	 mrr@10:0.1582	 epoch:25,24
recall@20:0.4949	 mrr@20:0.1671	 epoch:21,24
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-04-28 17:21:36.834478
	 train_loss : 21346.090
this_epoch----
recall@10:0.3648	 mrr@10:0.1581
recall@20:0.4945	 mrr@20:0.1671
best_result----
recall@10:0.3649	 mrr@10:0.1582	 epoch:25,24
recall@20:0.4949	 mrr@20:0.1671	 epoch:21,24
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-04-28 17:25:35.255649
	 train_loss : 21343.510
this_epoch----
recall@10:0.3647	 mrr@10:0.1581
recall@20:0.4944	 mrr@20:0.1671
best_result----
recall@10:0.3649	 mrr@10:0.1582	 epoch:25,24
recall@20:0.4949	 mrr@20:0.1671	 epoch:21,24
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-04-28 17:29:35.500994
	 train_loss : 21341.068
this_epoch----
recall@10:0.3645	 mrr@10:0.1579
recall@20:0.4944	 mrr@20:0.1669
best_result----
recall@10:0.3649	 mrr@10:0.1582	 epoch:25,24
recall@20:0.4949	 mrr@20:0.1671	 epoch:21,24
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-04-28 17:33:39.897843
	 train_loss : 21338.520
this_epoch----
recall@10:0.3644	 mrr@10:0.1580
recall@20:0.4945	 mrr@20:0.1670
best_result----
recall@10:0.3649	 mrr@10:0.1582	 epoch:25,24
recall@20:0.4949	 mrr@20:0.1671	 epoch:21,24
Done
