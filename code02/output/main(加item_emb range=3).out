nohup: ignoring input
Namespace(dataset='diginetica', emb_size=100, batch_size=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, temp=0.1, evaluate_k=[10, 20], epsilon=0.85, epoch=30, patience=10)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-04-26 15:16:21.180594
	 train_loss : 37823.266
this_epoch----
recall@10:0.3149	 mrr@10:0.1311
recall@20:0.4394	 mrr@20:0.1397
best_result----
recall@10:0.3149	 mrr@10:0.1311	 epoch:0,0
recall@20:0.4394	 mrr@20:0.1397	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-04-26 15:20:16.572910
	 train_loss : 28155.164
this_epoch----
recall@10:0.3242	 mrr@10:0.1364
recall@20:0.4517	 mrr@20:0.1452
best_result----
recall@10:0.3242	 mrr@10:0.1364	 epoch:1,1
recall@20:0.4517	 mrr@20:0.1452	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-04-26 15:24:11.842995
	 train_loss : 26886.297
this_epoch----
recall@10:0.3286	 mrr@10:0.1388
recall@20:0.4587	 mrr@20:0.1478
best_result----
recall@10:0.3286	 mrr@10:0.1388	 epoch:2,2
recall@20:0.4587	 mrr@20:0.1478	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-04-26 15:28:06.054049
	 train_loss : 26340.695
this_epoch----
recall@10:0.3350	 mrr@10:0.1409
recall@20:0.4629	 mrr@20:0.1497
best_result----
recall@10:0.3350	 mrr@10:0.1409	 epoch:3,3
recall@20:0.4629	 mrr@20:0.1497	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-04-26 15:32:09.183071
	 train_loss : 26023.473
this_epoch----
recall@10:0.3374	 mrr@10:0.1412
recall@20:0.4678	 mrr@20:0.1502
best_result----
recall@10:0.3374	 mrr@10:0.1412	 epoch:4,4
recall@20:0.4678	 mrr@20:0.1502	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-04-26 15:36:05.576673
	 train_loss : 25824.617
this_epoch----
recall@10:0.3387	 mrr@10:0.1425
recall@20:0.4674	 mrr@20:0.1513
best_result----
recall@10:0.3387	 mrr@10:0.1425	 epoch:5,5
recall@20:0.4678	 mrr@20:0.1513	 epoch:4,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-04-26 15:40:08.385449
	 train_loss : 25683.770
this_epoch----
recall@10:0.3389	 mrr@10:0.1430
recall@20:0.4685	 mrr@20:0.1519
best_result----
recall@10:0.3389	 mrr@10:0.1430	 epoch:6,6
recall@20:0.4685	 mrr@20:0.1519	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-04-26 15:44:02.209460
	 train_loss : 25588.805
this_epoch----
recall@10:0.3407	 mrr@10:0.1443
recall@20:0.4691	 mrr@20:0.1532
best_result----
recall@10:0.3407	 mrr@10:0.1443	 epoch:7,7
recall@20:0.4691	 mrr@20:0.1532	 epoch:7,7
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-04-26 15:47:56.976827
	 train_loss : 25517.822
this_epoch----
recall@10:0.3418	 mrr@10:0.1446
recall@20:0.4709	 mrr@20:0.1535
best_result----
recall@10:0.3418	 mrr@10:0.1446	 epoch:8,8
recall@20:0.4709	 mrr@20:0.1535	 epoch:8,8
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-04-26 15:51:49.398376
	 train_loss : 25456.451
this_epoch----
recall@10:0.3391	 mrr@10:0.1446
recall@20:0.4686	 mrr@20:0.1536
best_result----
recall@10:0.3418	 mrr@10:0.1446	 epoch:8,9
recall@20:0.4709	 mrr@20:0.1536	 epoch:8,9
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-04-26 15:55:41.976154
	 train_loss : 22837.891
this_epoch----
recall@10:0.3608	 mrr@10:0.1555
recall@20:0.4901	 mrr@20:0.1645
best_result----
recall@10:0.3608	 mrr@10:0.1555	 epoch:10,10
recall@20:0.4901	 mrr@20:0.1645	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-04-26 15:59:38.300679
	 train_loss : 22322.480
this_epoch----
recall@10:0.3621	 mrr@10:0.1560
recall@20:0.4925	 mrr@20:0.1650
best_result----
recall@10:0.3621	 mrr@10:0.1560	 epoch:11,11
recall@20:0.4925	 mrr@20:0.1650	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-04-26 16:03:35.280276
	 train_loss : 22160.123
this_epoch----
recall@10:0.3629	 mrr@10:0.1566
recall@20:0.4938	 mrr@20:0.1656
best_result----
recall@10:0.3629	 mrr@10:0.1566	 epoch:12,12
recall@20:0.4938	 mrr@20:0.1656	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-04-26 16:07:29.870039
	 train_loss : 22074.539
this_epoch----
recall@10:0.3627	 mrr@10:0.1570
recall@20:0.4941	 mrr@20:0.1661
best_result----
recall@10:0.3629	 mrr@10:0.1570	 epoch:12,13
recall@20:0.4941	 mrr@20:0.1661	 epoch:13,13
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-04-26 16:11:23.726911
	 train_loss : 22022.824
this_epoch----
recall@10:0.3630	 mrr@10:0.1569
recall@20:0.4938	 mrr@20:0.1660
best_result----
recall@10:0.3630	 mrr@10:0.1570	 epoch:14,13
recall@20:0.4941	 mrr@20:0.1661	 epoch:13,13
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-04-26 16:15:16.580584
	 train_loss : 21989.494
this_epoch----
recall@10:0.3646	 mrr@10:0.1570
recall@20:0.4937	 mrr@20:0.1659
best_result----
recall@10:0.3646	 mrr@10:0.1570	 epoch:15,13
recall@20:0.4941	 mrr@20:0.1661	 epoch:13,13
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-04-26 16:19:10.881052
	 train_loss : 21966.363
this_epoch----
recall@10:0.3630	 mrr@10:0.1567
recall@20:0.4944	 mrr@20:0.1658
best_result----
recall@10:0.3646	 mrr@10:0.1570	 epoch:15,13
recall@20:0.4944	 mrr@20:0.1661	 epoch:16,13
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-04-26 16:23:04.104839
	 train_loss : 21949.795
this_epoch----
recall@10:0.3642	 mrr@10:0.1575
recall@20:0.4936	 mrr@20:0.1665
best_result----
recall@10:0.3646	 mrr@10:0.1575	 epoch:15,17
recall@20:0.4944	 mrr@20:0.1665	 epoch:16,17
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-04-26 16:26:59.991561
	 train_loss : 21939.344
this_epoch----
recall@10:0.3645	 mrr@10:0.1570
recall@20:0.4938	 mrr@20:0.1659
best_result----
recall@10:0.3646	 mrr@10:0.1575	 epoch:15,17
recall@20:0.4944	 mrr@20:0.1665	 epoch:16,17
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-04-26 16:30:54.835255
	 train_loss : 21931.064
this_epoch----
recall@10:0.3634	 mrr@10:0.1576
recall@20:0.4937	 mrr@20:0.1666
best_result----
recall@10:0.3646	 mrr@10:0.1576	 epoch:15,19
recall@20:0.4944	 mrr@20:0.1666	 epoch:16,19
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-04-26 16:34:48.757974
	 train_loss : 21398.828
this_epoch----
recall@10:0.3633	 mrr@10:0.1577
recall@20:0.4944	 mrr@20:0.1668
best_result----
recall@10:0.3646	 mrr@10:0.1577	 epoch:15,20
recall@20:0.4944	 mrr@20:0.1668	 epoch:16,20
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-04-26 16:38:43.295522
	 train_loss : 21378.508
this_epoch----
recall@10:0.3637	 mrr@10:0.1578
recall@20:0.4944	 mrr@20:0.1669
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,21
recall@20:0.4944	 mrr@20:0.1669	 epoch:16,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-04-26 16:42:39.582742
	 train_loss : 21367.008
this_epoch----
recall@10:0.3641	 mrr@10:0.1578
recall@20:0.4947	 mrr@20:0.1668
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,21
recall@20:0.4947	 mrr@20:0.1669	 epoch:22,21
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-04-26 16:46:37.058181
	 train_loss : 21359.410
this_epoch----
recall@10:0.3643	 mrr@10:0.1578
recall@20:0.4947	 mrr@20:0.1669
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,23
recall@20:0.4947	 mrr@20:0.1669	 epoch:22,21
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-04-26 16:50:32.688543
	 train_loss : 21353.732
this_epoch----
recall@10:0.3640	 mrr@10:0.1578
recall@20:0.4949	 mrr@20:0.1669
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,23
recall@20:0.4949	 mrr@20:0.1669	 epoch:24,24
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-04-26 16:54:27.936856
	 train_loss : 21349.410
this_epoch----
recall@10:0.3641	 mrr@10:0.1578
recall@20:0.4949	 mrr@20:0.1669
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,23
recall@20:0.4949	 mrr@20:0.1669	 epoch:25,25
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-04-26 16:58:22.302290
	 train_loss : 21345.336
this_epoch----
recall@10:0.3641	 mrr@10:0.1577
recall@20:0.4946	 mrr@20:0.1667
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,23
recall@20:0.4949	 mrr@20:0.1669	 epoch:25,25
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-04-26 17:02:16.035659
	 train_loss : 21342.197
this_epoch----
recall@10:0.3644	 mrr@10:0.1577
recall@20:0.4947	 mrr@20:0.1668
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,23
recall@20:0.4949	 mrr@20:0.1669	 epoch:25,25
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-04-26 17:06:12.457448
	 train_loss : 21339.281
this_epoch----
recall@10:0.3639	 mrr@10:0.1577
recall@20:0.4948	 mrr@20:0.1667
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,23
recall@20:0.4949	 mrr@20:0.1669	 epoch:25,25
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-04-26 17:10:05.823595
	 train_loss : 21336.875
this_epoch----
recall@10:0.3642	 mrr@10:0.1577
recall@20:0.4947	 mrr@20:0.1668
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:15,23
recall@20:0.4949	 mrr@20:0.1669	 epoch:25,25
Done
