nohup: ignoring input
Namespace(batch_size=100, dataset='diginetica', emb_size=100, epoch=30, epsilon=0.85, evaluate_k=[10, 20], l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, patience=10, temp=0.1)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-04-08 13:10:45.886153
	 train_loss : 52053.863
this_epoch----
recall@10:0.0384	 mrr@10:0.0155
recall@20:0.0536	 mrr@20:0.0165
best_result----
recall@10:0.0384	 mrr@10:0.0155	 epoch:0,0
recall@20:0.0536	 mrr@20:0.0165	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-04-08 13:22:12.482662
	 train_loss : 46046.461
this_epoch----
recall@10:0.1411	 mrr@10:0.0553
recall@20:0.2021	 mrr@20:0.0595
best_result----
recall@10:0.1411	 mrr@10:0.0553	 epoch:1,1
recall@20:0.2021	 mrr@20:0.0595	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-04-08 13:33:24.557864
	 train_loss : 38869.004
this_epoch----
recall@10:0.2148	 mrr@10:0.0824
recall@20:0.3112	 mrr@20:0.0891
best_result----
recall@10:0.2148	 mrr@10:0.0824	 epoch:2,2
recall@20:0.3112	 mrr@20:0.0891	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-04-08 13:44:48.127533
	 train_loss : 34802.234
this_epoch----
recall@10:0.2383	 mrr@10:0.0933
recall@20:0.3427	 mrr@20:0.1005
best_result----
recall@10:0.2383	 mrr@10:0.0933	 epoch:3,3
recall@20:0.3427	 mrr@20:0.1005	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-04-08 13:56:16.166500
	 train_loss : 32946.574
this_epoch----
recall@10:0.2556	 mrr@10:0.1008
recall@20:0.3640	 mrr@20:0.1083
best_result----
recall@10:0.2556	 mrr@10:0.1008	 epoch:4,4
recall@20:0.3640	 mrr@20:0.1083	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-04-08 14:07:47.326358
	 train_loss : 31898.359
this_epoch----
recall@10:0.2653	 mrr@10:0.1049
recall@20:0.3763	 mrr@20:0.1125
best_result----
recall@10:0.2653	 mrr@10:0.1049	 epoch:5,5
recall@20:0.3763	 mrr@20:0.1125	 epoch:5,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-04-08 14:19:15.087903
	 train_loss : 31202.412
this_epoch----
recall@10:0.2726	 mrr@10:0.1088
recall@20:0.3858	 mrr@20:0.1166
best_result----
recall@10:0.2726	 mrr@10:0.1088	 epoch:6,6
recall@20:0.3858	 mrr@20:0.1166	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-04-08 14:30:40.845129
	 train_loss : 30709.436
this_epoch----
recall@10:0.2793	 mrr@10:0.1112
recall@20:0.3949	 mrr@20:0.1192
best_result----
recall@10:0.2793	 mrr@10:0.1112	 epoch:7,7
recall@20:0.3949	 mrr@20:0.1192	 epoch:7,7
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-04-08 14:42:09.008948
	 train_loss : 30343.100
this_epoch----
recall@10:0.2817	 mrr@10:0.1126
recall@20:0.3956	 mrr@20:0.1205
best_result----
recall@10:0.2817	 mrr@10:0.1126	 epoch:8,8
recall@20:0.3956	 mrr@20:0.1205	 epoch:8,8
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-04-08 14:50:51.812981
	 train_loss : 30048.967
this_epoch----
recall@10:0.2843	 mrr@10:0.1133
recall@20:0.3988	 mrr@20:0.1212
best_result----
recall@10:0.2843	 mrr@10:0.1133	 epoch:9,9
recall@20:0.3988	 mrr@20:0.1212	 epoch:9,9
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-04-08 14:59:32.223445
	 train_loss : 28874.869
this_epoch----
recall@10:0.3045	 mrr@10:0.1239
recall@20:0.4191	 mrr@20:0.1318
best_result----
recall@10:0.3045	 mrr@10:0.1239	 epoch:10,10
recall@20:0.4191	 mrr@20:0.1318	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-04-08 15:07:44.119087
	 train_loss : 28600.494
this_epoch----
recall@10:0.3043	 mrr@10:0.1244
recall@20:0.4201	 mrr@20:0.1324
best_result----
recall@10:0.3045	 mrr@10:0.1244	 epoch:10,11
recall@20:0.4201	 mrr@20:0.1324	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-04-08 15:15:55.383163
	 train_loss : 28496.471
this_epoch----
recall@10:0.3041	 mrr@10:0.1244
recall@20:0.4209	 mrr@20:0.1325
best_result----
recall@10:0.3045	 mrr@10:0.1244	 epoch:10,11
recall@20:0.4209	 mrr@20:0.1325	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-04-08 15:24:06.923952
	 train_loss : 28423.523
this_epoch----
recall@10:0.3050	 mrr@10:0.1245
recall@20:0.4211	 mrr@20:0.1325
best_result----
recall@10:0.3050	 mrr@10:0.1245	 epoch:13,13
recall@20:0.4211	 mrr@20:0.1325	 epoch:13,13
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-04-08 15:32:18.134609
	 train_loss : 28360.588
this_epoch----
recall@10:0.3044	 mrr@10:0.1246
recall@20:0.4209	 mrr@20:0.1327
best_result----
recall@10:0.3050	 mrr@10:0.1246	 epoch:13,14
recall@20:0.4211	 mrr@20:0.1327	 epoch:13,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-04-08 15:40:29.743766
	 train_loss : 28306.135
this_epoch----
recall@10:0.3053	 mrr@10:0.1248
recall@20:0.4212	 mrr@20:0.1328
best_result----
recall@10:0.3053	 mrr@10:0.1248	 epoch:15,15
recall@20:0.4212	 mrr@20:0.1328	 epoch:15,15
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-04-08 15:48:39.817728
	 train_loss : 28255.504
this_epoch----
recall@10:0.3053	 mrr@10:0.1245
recall@20:0.4212	 mrr@20:0.1325
best_result----
recall@10:0.3053	 mrr@10:0.1248	 epoch:15,15
recall@20:0.4212	 mrr@20:0.1328	 epoch:16,15
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-04-08 15:56:50.487492
	 train_loss : 28209.986
this_epoch----
recall@10:0.3049	 mrr@10:0.1247
recall@20:0.4207	 mrr@20:0.1327
best_result----
recall@10:0.3053	 mrr@10:0.1248	 epoch:15,15
recall@20:0.4212	 mrr@20:0.1328	 epoch:16,15
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-04-08 16:05:02.384667
	 train_loss : 28166.555
this_epoch----
recall@10:0.3045	 mrr@10:0.1244
recall@20:0.4210	 mrr@20:0.1325
best_result----
recall@10:0.3053	 mrr@10:0.1248	 epoch:15,15
recall@20:0.4212	 mrr@20:0.1328	 epoch:16,15
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-04-08 16:13:13.766326
	 train_loss : 28125.748
this_epoch----
recall@10:0.3041	 mrr@10:0.1248
recall@20:0.4216	 mrr@20:0.1329
best_result----
recall@10:0.3053	 mrr@10:0.1248	 epoch:15,19
recall@20:0.4216	 mrr@20:0.1329	 epoch:19,19
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-04-08 16:21:25.437879
	 train_loss : 27885.641
this_epoch----
recall@10:0.3047	 mrr@10:0.1247
recall@20:0.4215	 mrr@20:0.1328
best_result----
recall@10:0.3053	 mrr@10:0.1248	 epoch:15,19
recall@20:0.4216	 mrr@20:0.1329	 epoch:19,19
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-04-08 16:29:36.710308
	 train_loss : 27875.414
this_epoch----
recall@10:0.3047	 mrr@10:0.1250
recall@20:0.4218	 mrr@20:0.1331
best_result----
recall@10:0.3053	 mrr@10:0.1250	 epoch:15,21
recall@20:0.4218	 mrr@20:0.1331	 epoch:21,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-04-08 16:34:54.994288
	 train_loss : 27867.119
this_epoch----
recall@10:0.3052	 mrr@10:0.1251
recall@20:0.4221	 mrr@20:0.1332
best_result----
recall@10:0.3053	 mrr@10:0.1251	 epoch:15,22
recall@20:0.4221	 mrr@20:0.1332	 epoch:22,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-04-08 16:40:10.403692
	 train_loss : 27860.195
this_epoch----
recall@10:0.3049	 mrr@10:0.1252
recall@20:0.4218	 mrr@20:0.1333
best_result----
recall@10:0.3053	 mrr@10:0.1252	 epoch:15,23
recall@20:0.4221	 mrr@20:0.1333	 epoch:22,23
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-04-08 16:45:28.287297
	 train_loss : 27853.955
this_epoch----
recall@10:0.3053	 mrr@10:0.1252
recall@20:0.4219	 mrr@20:0.1332
best_result----
recall@10:0.3053	 mrr@10:0.1252	 epoch:15,23
recall@20:0.4221	 mrr@20:0.1333	 epoch:22,23
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-04-08 16:50:45.484443
	 train_loss : 27848.240
this_epoch----
recall@10:0.3051	 mrr@10:0.1253
recall@20:0.4218	 mrr@20:0.1334
best_result----
recall@10:0.3053	 mrr@10:0.1253	 epoch:15,25
recall@20:0.4221	 mrr@20:0.1334	 epoch:22,25
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-04-08 16:57:17.818972
	 train_loss : 27842.508
this_epoch----
recall@10:0.3050	 mrr@10:0.1253
recall@20:0.4218	 mrr@20:0.1334
best_result----
recall@10:0.3053	 mrr@10:0.1253	 epoch:15,25
recall@20:0.4221	 mrr@20:0.1334	 epoch:22,25
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-04-08 17:05:13.988767
	 train_loss : 27837.400
this_epoch----
recall@10:0.3052	 mrr@10:0.1252
recall@20:0.4218	 mrr@20:0.1333
best_result----
recall@10:0.3053	 mrr@10:0.1253	 epoch:15,25
recall@20:0.4221	 mrr@20:0.1334	 epoch:22,25
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-04-08 17:13:10.270788
	 train_loss : 27832.223
this_epoch----
recall@10:0.3054	 mrr@10:0.1253
recall@20:0.4216	 mrr@20:0.1333
best_result----
recall@10:0.3054	 mrr@10:0.1253	 epoch:28,25
recall@20:0.4221	 mrr@20:0.1334	 epoch:22,25
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-04-08 17:21:05.278890
	 train_loss : 27827.609
this_epoch----
recall@10:0.3056	 mrr@10:0.1253
recall@20:0.4216	 mrr@20:0.1334
best_result----
recall@10:0.3056	 mrr@10:0.1253	 epoch:29,29
recall@20:0.4221	 mrr@20:0.1334	 epoch:22,25
Done
