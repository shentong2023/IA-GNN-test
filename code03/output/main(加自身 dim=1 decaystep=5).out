nohup: ignoring input
Namespace(batch_size=100, dataset='diginetica', emb_size=100, epoch=30, epsilon=0.85, evaluate_k=[10, 20], l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=5, n_heads=3, n_intentions=3, patience=10, temp=0.1)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-04-08 10:54:48.793083
	 train_loss : 47480.672
this_epoch----
recall@10:0.1621	 mrr@10:0.0610
recall@20:0.2349	 mrr@20:0.0660
best_result----
recall@10:0.1621	 mrr@10:0.0610	 epoch:0,0
recall@20:0.2349	 mrr@20:0.0660	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-04-08 11:02:59.681876
	 train_loss : 34061.023
this_epoch----
recall@10:0.2555	 mrr@10:0.0990
recall@20:0.3663	 mrr@20:0.1067
best_result----
recall@10:0.2555	 mrr@10:0.0990	 epoch:1,1
recall@20:0.3663	 mrr@20:0.1067	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-04-08 11:11:21.159724
	 train_loss : 29572.859
this_epoch----
recall@10:0.2897	 mrr@10:0.1164
recall@20:0.4083	 mrr@20:0.1246
best_result----
recall@10:0.2897	 mrr@10:0.1164	 epoch:2,2
recall@20:0.4083	 mrr@20:0.1246	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-04-08 11:19:24.225331
	 train_loss : 27807.973
this_epoch----
recall@10:0.3010	 mrr@10:0.1197
recall@20:0.4232	 mrr@20:0.1281
best_result----
recall@10:0.3010	 mrr@10:0.1197	 epoch:3,3
recall@20:0.4232	 mrr@20:0.1281	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-04-08 11:27:24.528085
	 train_loss : 26754.768
this_epoch----
recall@10:0.3068	 mrr@10:0.1242
recall@20:0.4320	 mrr@20:0.1328
best_result----
recall@10:0.3068	 mrr@10:0.1242	 epoch:4,4
recall@20:0.4320	 mrr@20:0.1328	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.0001
start training... 2022-04-08 11:35:25.067830
	 train_loss : 23639.285
this_epoch----
recall@10:0.3407	 mrr@10:0.1443
recall@20:0.4673	 mrr@20:0.1530
best_result----
recall@10:0.3407	 mrr@10:0.1443	 epoch:5,5
recall@20:0.4673	 mrr@20:0.1530	 epoch:5,5
--------------------------------------
epoch 6
lr: 0.0001
start training... 2022-04-08 11:43:25.502837
	 train_loss : 23057.648
this_epoch----
recall@10:0.3414	 mrr@10:0.1450
recall@20:0.4676	 mrr@20:0.1537
best_result----
recall@10:0.3414	 mrr@10:0.1450	 epoch:6,6
recall@20:0.4676	 mrr@20:0.1537	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.0001
start training... 2022-04-08 11:51:25.871271
	 train_loss : 22847.148
this_epoch----
recall@10:0.3405	 mrr@10:0.1447
recall@20:0.4660	 mrr@20:0.1534
best_result----
recall@10:0.3414	 mrr@10:0.1450	 epoch:6,6
recall@20:0.4676	 mrr@20:0.1537	 epoch:6,6
--------------------------------------
epoch 8
lr: 0.0001
start training... 2022-04-08 11:59:27.419051
	 train_loss : 22681.012
this_epoch----
recall@10:0.3421	 mrr@10:0.1458
recall@20:0.4666	 mrr@20:0.1544
best_result----
recall@10:0.3421	 mrr@10:0.1458	 epoch:8,8
recall@20:0.4676	 mrr@20:0.1544	 epoch:6,8
--------------------------------------
epoch 9
lr: 0.0001
start training... 2022-04-08 12:07:28.081567
	 train_loss : 22536.699
this_epoch----
recall@10:0.3426	 mrr@10:0.1455
recall@20:0.4679	 mrr@20:0.1542
best_result----
recall@10:0.3426	 mrr@10:0.1458	 epoch:9,8
recall@20:0.4679	 mrr@20:0.1544	 epoch:9,8
--------------------------------------
epoch 10
lr: 1e-05
start training... 2022-04-08 12:14:31.277672
	 train_loss : 22004.992
this_epoch----
recall@10:0.3430	 mrr@10:0.1461
recall@20:0.4683	 mrr@20:0.1548
best_result----
recall@10:0.3430	 mrr@10:0.1461	 epoch:10,10
recall@20:0.4683	 mrr@20:0.1548	 epoch:10,10
--------------------------------------
epoch 11
lr: 1e-05
start training... 2022-04-08 12:20:26.665885
	 train_loss : 21962.283
this_epoch----
recall@10:0.3432	 mrr@10:0.1463
recall@20:0.4688	 mrr@20:0.1550
best_result----
recall@10:0.3432	 mrr@10:0.1463	 epoch:11,11
recall@20:0.4688	 mrr@20:0.1550	 epoch:11,11
--------------------------------------
epoch 12
lr: 1e-05
start training... 2022-04-08 12:26:17.488031
	 train_loss : 21934.068
this_epoch----
recall@10:0.3436	 mrr@10:0.1465
recall@20:0.4691	 mrr@20:0.1552
best_result----
recall@10:0.3436	 mrr@10:0.1465	 epoch:12,12
recall@20:0.4691	 mrr@20:0.1552	 epoch:12,12
--------------------------------------
epoch 13
lr: 1e-05
start training... 2022-04-08 12:32:05.876979
	 train_loss : 21912.545
this_epoch----
recall@10:0.3444	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1467	 epoch:13,13
recall@20:0.4693	 mrr@20:0.1554	 epoch:13,13
--------------------------------------
epoch 14
lr: 1e-05
start training... 2022-04-08 12:37:37.157708
	 train_loss : 21894.469
this_epoch----
recall@10:0.3441	 mrr@10:0.1468
recall@20:0.4692	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4693	 mrr@20:0.1554	 epoch:13,14
--------------------------------------
epoch 15
lr: 1.0000000000000002e-06
start training... 2022-04-08 12:43:14.087852
	 train_loss : 21820.027
this_epoch----
recall@10:0.3440	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4693	 mrr@20:0.1554	 epoch:13,14
--------------------------------------
epoch 16
lr: 1.0000000000000002e-06
start training... 2022-04-08 12:48:56.557457
	 train_loss : 21818.246
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4693	 mrr@20:0.1554	 epoch:13,14
--------------------------------------
epoch 17
lr: 1.0000000000000002e-06
start training... 2022-04-08 12:54:32.411336
	 train_loss : 21816.564
this_epoch----
recall@10:0.3440	 mrr@10:0.1467
recall@20:0.4694	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 18
lr: 1.0000000000000002e-06
start training... 2022-04-08 13:00:05.526702
	 train_loss : 21814.861
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 19
lr: 1.0000000000000002e-06
start training... 2022-04-08 13:06:03.755639
	 train_loss : 21813.256
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 20
lr: 1.0000000000000002e-07
start training... 2022-04-08 13:15:20.714884
	 train_loss : 21805.430
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 21
lr: 1.0000000000000002e-07
start training... 2022-04-08 13:26:28.434753
	 train_loss : 21805.131
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 22
lr: 1.0000000000000002e-07
start training... 2022-04-08 13:37:51.904262
	 train_loss : 21805.074
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 23
lr: 1.0000000000000002e-07
start training... 2022-04-08 13:48:45.803157
	 train_loss : 21804.777
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 24
lr: 1.0000000000000002e-07
start training... 2022-04-08 13:59:47.318400
	 train_loss : 21804.609
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 25
lr: 1.0000000000000004e-08
start training... 2022-04-08 14:10:38.348320
	 train_loss : 21803.908
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 26
lr: 1.0000000000000004e-08
start training... 2022-04-08 14:21:36.251440
	 train_loss : 21803.770
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
--------------------------------------
epoch 27
lr: 1.0000000000000004e-08
start training... 2022-04-08 14:32:31.587508
	 train_loss : 21803.947
this_epoch----
recall@10:0.3441	 mrr@10:0.1467
recall@20:0.4693	 mrr@20:0.1554
best_result----
recall@10:0.3444	 mrr@10:0.1468	 epoch:13,14
recall@20:0.4694	 mrr@20:0.1554	 epoch:17,14
Done
