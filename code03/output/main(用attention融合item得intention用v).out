nohup: ignoring input
Namespace(batch_size=100, dataset='diginetica', emb_size=100, epoch=30, epsilon=0.85, evaluate_k=[10, 20], l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, patience=10, temp=0.1)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-04-07 14:56:17.962785
	 train_loss : 49188.434
this_epoch----
recall@10:0.1335	 mrr@10:0.0490
recall@20:0.1974	 mrr@20:0.0533
best_result----
recall@10:0.1335	 mrr@10:0.0490	 epoch:0,0
recall@20:0.1974	 mrr@20:0.0533	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-04-07 15:03:31.043144
	 train_loss : 34954.793
this_epoch----
recall@10:0.2499	 mrr@10:0.0938
recall@20:0.3628	 mrr@20:0.1016
best_result----
recall@10:0.2499	 mrr@10:0.0938	 epoch:1,1
recall@20:0.3628	 mrr@20:0.1016	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-04-07 15:10:44.661078
	 train_loss : 29720.645
this_epoch----
recall@10:0.2837	 mrr@10:0.1117
recall@20:0.4026	 mrr@20:0.1199
best_result----
recall@10:0.2837	 mrr@10:0.1117	 epoch:2,2
recall@20:0.4026	 mrr@20:0.1199	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-04-07 15:17:57.466696
	 train_loss : 27776.855
this_epoch----
recall@10:0.2949	 mrr@10:0.1167
recall@20:0.4165	 mrr@20:0.1251
best_result----
recall@10:0.2949	 mrr@10:0.1167	 epoch:3,3
recall@20:0.4165	 mrr@20:0.1251	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-04-07 15:25:10.043554
	 train_loss : 26635.973
this_epoch----
recall@10:0.3049	 mrr@10:0.1213
recall@20:0.4276	 mrr@20:0.1298
best_result----
recall@10:0.3049	 mrr@10:0.1213	 epoch:4,4
recall@20:0.4276	 mrr@20:0.1298	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-04-07 15:32:18.728291
	 train_loss : 25804.527
this_epoch----
recall@10:0.3086	 mrr@10:0.1229
recall@20:0.4297	 mrr@20:0.1312
best_result----
recall@10:0.3086	 mrr@10:0.1229	 epoch:5,5
recall@20:0.4297	 mrr@20:0.1312	 epoch:5,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-04-07 15:39:19.702059
	 train_loss : 25137.607
this_epoch----
recall@10:0.3064	 mrr@10:0.1229
recall@20:0.4293	 mrr@20:0.1314
best_result----
recall@10:0.3086	 mrr@10:0.1229	 epoch:5,6
recall@20:0.4297	 mrr@20:0.1314	 epoch:5,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-04-07 15:46:31.908992
	 train_loss : 24575.527
this_epoch----
recall@10:0.3067	 mrr@10:0.1232
recall@20:0.4298	 mrr@20:0.1317
best_result----
recall@10:0.3086	 mrr@10:0.1232	 epoch:5,7
recall@20:0.4298	 mrr@20:0.1317	 epoch:7,7
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-04-07 15:53:43.909391
	 train_loss : 24085.008
this_epoch----
recall@10:0.3083	 mrr@10:0.1237
recall@20:0.4304	 mrr@20:0.1321
best_result----
recall@10:0.3086	 mrr@10:0.1237	 epoch:5,8
recall@20:0.4304	 mrr@20:0.1321	 epoch:8,8
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-04-07 16:00:59.121735
	 train_loss : 23630.928
this_epoch----
recall@10:0.3063	 mrr@10:0.1209
recall@20:0.4265	 mrr@20:0.1292
best_result----
recall@10:0.3086	 mrr@10:0.1237	 epoch:5,8
recall@20:0.4304	 mrr@20:0.1321	 epoch:8,8
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-04-07 16:08:12.831026
	 train_loss : 20469.988
this_epoch----
recall@10:0.3276	 mrr@10:0.1346
recall@20:0.4492	 mrr@20:0.1430
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-04-07 16:14:03.281470
	 train_loss : 19875.266
this_epoch----
recall@10:0.3272	 mrr@10:0.1339
recall@20:0.4479	 mrr@20:0.1422
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-04-07 16:17:52.611292
	 train_loss : 19654.061
this_epoch----
recall@10:0.3248	 mrr@10:0.1336
recall@20:0.4458	 mrr@20:0.1420
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-04-07 16:21:40.594162
	 train_loss : 19484.689
this_epoch----
recall@10:0.3248	 mrr@10:0.1322
recall@20:0.4451	 mrr@20:0.1405
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-04-07 16:25:27.813976
	 train_loss : 19339.410
this_epoch----
recall@10:0.3225	 mrr@10:0.1312
recall@20:0.4432	 mrr@20:0.1396
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-04-07 16:29:15.561188
	 train_loss : 19210.939
this_epoch----
recall@10:0.3207	 mrr@10:0.1307
recall@20:0.4421	 mrr@20:0.1391
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-04-07 16:33:08.289598
	 train_loss : 19091.295
this_epoch----
recall@10:0.3199	 mrr@10:0.1297
recall@20:0.4408	 mrr@20:0.1380
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-04-07 16:36:56.135526
	 train_loss : 18979.408
this_epoch----
recall@10:0.3167	 mrr@10:0.1294
recall@20:0.4390	 mrr@20:0.1379
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-04-07 16:40:44.277323
	 train_loss : 18874.590
this_epoch----
recall@10:0.3172	 mrr@10:0.1284
recall@20:0.4381	 mrr@20:0.1367
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-04-07 16:44:35.677100
	 train_loss : 18772.523
this_epoch----
recall@10:0.3165	 mrr@10:0.1276
recall@20:0.4368	 mrr@20:0.1359
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-04-07 16:48:24.312100
	 train_loss : 18192.555
this_epoch----
recall@10:0.3165	 mrr@10:0.1283
recall@20:0.4376	 mrr@20:0.1367
best_result----
recall@10:0.3276	 mrr@10:0.1346	 epoch:10,10
recall@20:0.4492	 mrr@20:0.1430	 epoch:10,10
Done
