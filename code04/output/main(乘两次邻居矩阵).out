nohup: ignoring input
Namespace(dataset='diginetica', emb_size=100, batch_size=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, temp=0.1, evaluate_k=[10, 20], epsilon=0.85, epoch=30, patience=10)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-05-05 15:50:11.339170
	 train_loss : 37849.852
this_epoch----
recall@10:0.3137	 mrr@10:0.1324
recall@20:0.4410	 mrr@20:0.1411
best_result----
recall@10:0.3137	 mrr@10:0.1324	 epoch:0,0
recall@20:0.4410	 mrr@20:0.1411	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-05-05 15:54:06.781262
	 train_loss : 28095.658
this_epoch----
recall@10:0.3250	 mrr@10:0.1356
recall@20:0.4532	 mrr@20:0.1445
best_result----
recall@10:0.3250	 mrr@10:0.1356	 epoch:1,1
recall@20:0.4532	 mrr@20:0.1445	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-05-05 15:58:02.618379
	 train_loss : 26875.480
this_epoch----
recall@10:0.3305	 mrr@10:0.1385
recall@20:0.4584	 mrr@20:0.1472
best_result----
recall@10:0.3305	 mrr@10:0.1385	 epoch:2,2
recall@20:0.4584	 mrr@20:0.1472	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-05-05 16:01:57.761585
	 train_loss : 26337.893
this_epoch----
recall@10:0.3308	 mrr@10:0.1391
recall@20:0.4594	 mrr@20:0.1480
best_result----
recall@10:0.3308	 mrr@10:0.1391	 epoch:3,3
recall@20:0.4594	 mrr@20:0.1480	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-05-05 16:05:53.287708
	 train_loss : 26020.953
this_epoch----
recall@10:0.3372	 mrr@10:0.1410
recall@20:0.4662	 mrr@20:0.1499
best_result----
recall@10:0.3372	 mrr@10:0.1410	 epoch:4,4
recall@20:0.4662	 mrr@20:0.1499	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-05-05 16:09:48.726321
	 train_loss : 25824.410
this_epoch----
recall@10:0.3338	 mrr@10:0.1414
recall@20:0.4646	 mrr@20:0.1505
best_result----
recall@10:0.3372	 mrr@10:0.1414	 epoch:4,5
recall@20:0.4662	 mrr@20:0.1505	 epoch:4,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-05-05 16:13:43.800248
	 train_loss : 25676.947
this_epoch----
recall@10:0.3380	 mrr@10:0.1433
recall@20:0.4684	 mrr@20:0.1523
best_result----
recall@10:0.3380	 mrr@10:0.1433	 epoch:6,6
recall@20:0.4684	 mrr@20:0.1523	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-05-05 16:17:38.858190
	 train_loss : 25581.031
this_epoch----
recall@10:0.3377	 mrr@10:0.1433
recall@20:0.4666	 mrr@20:0.1521
best_result----
recall@10:0.3380	 mrr@10:0.1433	 epoch:6,7
recall@20:0.4684	 mrr@20:0.1523	 epoch:6,6
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-05-05 16:21:33.347932
	 train_loss : 25512.186
this_epoch----
recall@10:0.3375	 mrr@10:0.1440
recall@20:0.4682	 mrr@20:0.1530
best_result----
recall@10:0.3380	 mrr@10:0.1440	 epoch:6,8
recall@20:0.4684	 mrr@20:0.1530	 epoch:6,8
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-05-05 16:25:28.562460
	 train_loss : 25451.963
this_epoch----
recall@10:0.3404	 mrr@10:0.1431
recall@20:0.4700	 mrr@20:0.1521
best_result----
recall@10:0.3404	 mrr@10:0.1440	 epoch:9,8
recall@20:0.4700	 mrr@20:0.1530	 epoch:9,8
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-05-05 16:29:22.378868
	 train_loss : 22814.547
this_epoch----
recall@10:0.3604	 mrr@10:0.1546
recall@20:0.4886	 mrr@20:0.1635
best_result----
recall@10:0.3604	 mrr@10:0.1546	 epoch:10,10
recall@20:0.4886	 mrr@20:0.1635	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-05-05 16:33:16.818492
	 train_loss : 22310.373
this_epoch----
recall@10:0.3626	 mrr@10:0.1562
recall@20:0.4922	 mrr@20:0.1652
best_result----
recall@10:0.3626	 mrr@10:0.1562	 epoch:11,11
recall@20:0.4922	 mrr@20:0.1652	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-05-05 16:37:11.481552
	 train_loss : 22152.650
this_epoch----
recall@10:0.3621	 mrr@10:0.1563
recall@20:0.4940	 mrr@20:0.1654
best_result----
recall@10:0.3626	 mrr@10:0.1563	 epoch:11,12
recall@20:0.4940	 mrr@20:0.1654	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-05-05 16:41:06.747661
	 train_loss : 22070.824
this_epoch----
recall@10:0.3637	 mrr@10:0.1566
recall@20:0.4936	 mrr@20:0.1656
best_result----
recall@10:0.3637	 mrr@10:0.1566	 epoch:13,13
recall@20:0.4940	 mrr@20:0.1656	 epoch:12,13
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-05-05 16:45:02.172541
	 train_loss : 22021.727
this_epoch----
recall@10:0.3632	 mrr@10:0.1568
recall@20:0.4933	 mrr@20:0.1658
best_result----
recall@10:0.3637	 mrr@10:0.1568	 epoch:13,14
recall@20:0.4940	 mrr@20:0.1658	 epoch:12,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-05-05 16:48:57.485227
	 train_loss : 21989.371
this_epoch----
recall@10:0.3636	 mrr@10:0.1569
recall@20:0.4942	 mrr@20:0.1659
best_result----
recall@10:0.3637	 mrr@10:0.1569	 epoch:13,15
recall@20:0.4942	 mrr@20:0.1659	 epoch:15,15
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-05-05 16:52:51.869679
	 train_loss : 21968.006
this_epoch----
recall@10:0.3641	 mrr@10:0.1573
recall@20:0.4938	 mrr@20:0.1663
best_result----
recall@10:0.3641	 mrr@10:0.1573	 epoch:16,16
recall@20:0.4942	 mrr@20:0.1663	 epoch:15,16
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-05-05 16:56:46.498861
	 train_loss : 21953.674
this_epoch----
recall@10:0.3626	 mrr@10:0.1567
recall@20:0.4941	 mrr@20:0.1658
best_result----
recall@10:0.3641	 mrr@10:0.1573	 epoch:16,16
recall@20:0.4942	 mrr@20:0.1663	 epoch:15,16
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-05-05 17:00:40.721286
	 train_loss : 21943.871
this_epoch----
recall@10:0.3640	 mrr@10:0.1567
recall@20:0.4940	 mrr@20:0.1657
best_result----
recall@10:0.3641	 mrr@10:0.1573	 epoch:16,16
recall@20:0.4942	 mrr@20:0.1663	 epoch:15,16
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-05-05 17:04:35.219389
	 train_loss : 21938.072
this_epoch----
recall@10:0.3635	 mrr@10:0.1571
recall@20:0.4940	 mrr@20:0.1661
best_result----
recall@10:0.3641	 mrr@10:0.1573	 epoch:16,16
recall@20:0.4942	 mrr@20:0.1663	 epoch:15,16
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-05-05 17:08:29.617024
	 train_loss : 21406.516
this_epoch----
recall@10:0.3639	 mrr@10:0.1574
recall@20:0.4939	 mrr@20:0.1664
best_result----
recall@10:0.3641	 mrr@10:0.1574	 epoch:16,20
recall@20:0.4942	 mrr@20:0.1664	 epoch:15,20
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-05-05 17:12:24.379283
	 train_loss : 21386.766
this_epoch----
recall@10:0.3641	 mrr@10:0.1575
recall@20:0.4941	 mrr@20:0.1665
best_result----
recall@10:0.3641	 mrr@10:0.1575	 epoch:16,21
recall@20:0.4942	 mrr@20:0.1665	 epoch:15,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-05-05 17:16:18.740297
	 train_loss : 21375.852
this_epoch----
recall@10:0.3640	 mrr@10:0.1575
recall@20:0.4942	 mrr@20:0.1665
best_result----
recall@10:0.3641	 mrr@10:0.1575	 epoch:16,22
recall@20:0.4942	 mrr@20:0.1665	 epoch:22,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-05-05 17:20:13.043768
	 train_loss : 21368.719
this_epoch----
recall@10:0.3641	 mrr@10:0.1575
recall@20:0.4942	 mrr@20:0.1665
best_result----
recall@10:0.3641	 mrr@10:0.1575	 epoch:16,23
recall@20:0.4942	 mrr@20:0.1665	 epoch:22,22
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-05-05 17:24:07.567800
	 train_loss : 21363.641
this_epoch----
recall@10:0.3639	 mrr@10:0.1574
recall@20:0.4945	 mrr@20:0.1665
best_result----
recall@10:0.3641	 mrr@10:0.1575	 epoch:16,23
recall@20:0.4945	 mrr@20:0.1665	 epoch:24,22
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-05-05 17:28:01.961570
	 train_loss : 21359.191
this_epoch----
recall@10:0.3640	 mrr@10:0.1575
recall@20:0.4944	 mrr@20:0.1666
best_result----
recall@10:0.3641	 mrr@10:0.1575	 epoch:16,25
recall@20:0.4945	 mrr@20:0.1666	 epoch:24,25
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-05-05 17:31:56.408667
	 train_loss : 21355.789
this_epoch----
recall@10:0.3644	 mrr@10:0.1578
recall@20:0.4943	 mrr@20:0.1668
best_result----
recall@10:0.3644	 mrr@10:0.1578	 epoch:26,26
recall@20:0.4945	 mrr@20:0.1668	 epoch:24,26
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-05-05 17:35:51.226564
	 train_loss : 21352.779
this_epoch----
recall@10:0.3646	 mrr@10:0.1577
recall@20:0.4944	 mrr@20:0.1667
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:27,26
recall@20:0.4945	 mrr@20:0.1668	 epoch:24,26
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-05-05 17:39:45.720773
	 train_loss : 21350.314
this_epoch----
recall@10:0.3646	 mrr@10:0.1576
recall@20:0.4942	 mrr@20:0.1666
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:27,26
recall@20:0.4945	 mrr@20:0.1668	 epoch:24,26
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-05-05 17:43:40.356934
	 train_loss : 21347.852
this_epoch----
recall@10:0.3644	 mrr@10:0.1577
recall@20:0.4945	 mrr@20:0.1667
best_result----
recall@10:0.3646	 mrr@10:0.1578	 epoch:27,26
recall@20:0.4945	 mrr@20:0.1668	 epoch:24,26
Done
