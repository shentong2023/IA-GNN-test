nohup: ignoring input
Namespace(dataset='diginetica', emb_size=100, batch_size=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, temp=0.1, evaluate_k=[10, 20], epsilon=0.85, epoch=30, patience=10)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-05-05 19:22:01.448427
	 train_loss : 37044.176
this_epoch----
recall@10:0.3131	 mrr@10:0.1300
recall@20:0.4402	 mrr@20:0.1387
best_result----
recall@10:0.3131	 mrr@10:0.1300	 epoch:0,0
recall@20:0.4402	 mrr@20:0.1387	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-05-05 19:25:54.134966
	 train_loss : 28065.125
this_epoch----
recall@10:0.3247	 mrr@10:0.1355
recall@20:0.4533	 mrr@20:0.1443
best_result----
recall@10:0.3247	 mrr@10:0.1355	 epoch:1,1
recall@20:0.4533	 mrr@20:0.1443	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-05-05 19:29:47.240195
	 train_loss : 26868.865
this_epoch----
recall@10:0.3311	 mrr@10:0.1383
recall@20:0.4613	 mrr@20:0.1473
best_result----
recall@10:0.3311	 mrr@10:0.1383	 epoch:2,2
recall@20:0.4613	 mrr@20:0.1473	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-05-05 19:33:42.917588
	 train_loss : 26331.334
this_epoch----
recall@10:0.3341	 mrr@10:0.1404
recall@20:0.4632	 mrr@20:0.1492
best_result----
recall@10:0.3341	 mrr@10:0.1404	 epoch:3,3
recall@20:0.4632	 mrr@20:0.1492	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-05-05 19:37:40.236977
	 train_loss : 26023.910
this_epoch----
recall@10:0.3328	 mrr@10:0.1410
recall@20:0.4648	 mrr@20:0.1501
best_result----
recall@10:0.3341	 mrr@10:0.1410	 epoch:3,4
recall@20:0.4648	 mrr@20:0.1501	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-05-05 19:41:37.757965
	 train_loss : 25827.799
this_epoch----
recall@10:0.3377	 mrr@10:0.1412
recall@20:0.4660	 mrr@20:0.1501
best_result----
recall@10:0.3377	 mrr@10:0.1412	 epoch:5,5
recall@20:0.4660	 mrr@20:0.1501	 epoch:5,4
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-05-05 19:45:37.057767
	 train_loss : 25693.006
this_epoch----
recall@10:0.3382	 mrr@10:0.1429
recall@20:0.4669	 mrr@20:0.1517
best_result----
recall@10:0.3382	 mrr@10:0.1429	 epoch:6,6
recall@20:0.4669	 mrr@20:0.1517	 epoch:6,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-05-05 19:49:38.201574
	 train_loss : 25594.434
this_epoch----
recall@10:0.3385	 mrr@10:0.1436
recall@20:0.4680	 mrr@20:0.1525
best_result----
recall@10:0.3385	 mrr@10:0.1436	 epoch:7,7
recall@20:0.4680	 mrr@20:0.1525	 epoch:7,7
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-05-05 19:53:40.679245
	 train_loss : 25533.076
this_epoch----
recall@10:0.3411	 mrr@10:0.1428
recall@20:0.4680	 mrr@20:0.1516
best_result----
recall@10:0.3411	 mrr@10:0.1436	 epoch:8,7
recall@20:0.4680	 mrr@20:0.1525	 epoch:7,7
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-05-05 19:57:31.989091
	 train_loss : 25466.762
this_epoch----
recall@10:0.3361	 mrr@10:0.1419
recall@20:0.4662	 mrr@20:0.1509
best_result----
recall@10:0.3411	 mrr@10:0.1436	 epoch:8,7
recall@20:0.4680	 mrr@20:0.1525	 epoch:7,7
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-05-05 20:01:29.250947
	 train_loss : 22840.990
this_epoch----
recall@10:0.3608	 mrr@10:0.1546
recall@20:0.4892	 mrr@20:0.1634
best_result----
recall@10:0.3608	 mrr@10:0.1546	 epoch:10,10
recall@20:0.4892	 mrr@20:0.1634	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-05-05 20:05:27.246985
	 train_loss : 22328.607
this_epoch----
recall@10:0.3626	 mrr@10:0.1561
recall@20:0.4926	 mrr@20:0.1651
best_result----
recall@10:0.3626	 mrr@10:0.1561	 epoch:11,11
recall@20:0.4926	 mrr@20:0.1651	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-05-05 20:09:24.347281
	 train_loss : 22170.486
this_epoch----
recall@10:0.3639	 mrr@10:0.1567
recall@20:0.4936	 mrr@20:0.1656
best_result----
recall@10:0.3639	 mrr@10:0.1567	 epoch:12,12
recall@20:0.4936	 mrr@20:0.1656	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-05-05 20:13:24.445164
	 train_loss : 22089.016
this_epoch----
recall@10:0.3640	 mrr@10:0.1570
recall@20:0.4934	 mrr@20:0.1660
best_result----
recall@10:0.3640	 mrr@10:0.1570	 epoch:13,13
recall@20:0.4936	 mrr@20:0.1660	 epoch:12,13
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-05-05 20:17:29.316311
	 train_loss : 22038.404
this_epoch----
recall@10:0.3636	 mrr@10:0.1572
recall@20:0.4940	 mrr@20:0.1662
best_result----
recall@10:0.3640	 mrr@10:0.1572	 epoch:13,14
recall@20:0.4940	 mrr@20:0.1662	 epoch:14,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-05-05 20:21:26.353205
	 train_loss : 22006.812
this_epoch----
recall@10:0.3643	 mrr@10:0.1576
recall@20:0.4936	 mrr@20:0.1665
best_result----
recall@10:0.3643	 mrr@10:0.1576	 epoch:15,15
recall@20:0.4940	 mrr@20:0.1665	 epoch:14,15
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-05-05 20:25:23.095922
	 train_loss : 21986.344
this_epoch----
recall@10:0.3639	 mrr@10:0.1572
recall@20:0.4940	 mrr@20:0.1662
best_result----
recall@10:0.3643	 mrr@10:0.1576	 epoch:15,15
recall@20:0.4940	 mrr@20:0.1665	 epoch:14,15
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-05-05 20:29:19.482353
	 train_loss : 21970.139
this_epoch----
recall@10:0.3634	 mrr@10:0.1568
recall@20:0.4934	 mrr@20:0.1659
best_result----
recall@10:0.3643	 mrr@10:0.1576	 epoch:15,15
recall@20:0.4940	 mrr@20:0.1665	 epoch:14,15
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-05-05 20:33:16.186477
	 train_loss : 21959.930
this_epoch----
recall@10:0.3641	 mrr@10:0.1577
recall@20:0.4941	 mrr@20:0.1667
best_result----
recall@10:0.3643	 mrr@10:0.1577	 epoch:15,18
recall@20:0.4941	 mrr@20:0.1667	 epoch:18,18
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-05-05 20:37:13.506387
	 train_loss : 21953.189
this_epoch----
recall@10:0.3637	 mrr@10:0.1575
recall@20:0.4940	 mrr@20:0.1666
best_result----
recall@10:0.3643	 mrr@10:0.1577	 epoch:15,18
recall@20:0.4941	 mrr@20:0.1667	 epoch:18,18
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-05-05 20:41:10.518225
	 train_loss : 21418.225
this_epoch----
recall@10:0.3649	 mrr@10:0.1580
recall@20:0.4945	 mrr@20:0.1670
best_result----
recall@10:0.3649	 mrr@10:0.1580	 epoch:20,20
recall@20:0.4945	 mrr@20:0.1670	 epoch:20,20
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-05-05 20:45:12.978378
	 train_loss : 21399.465
this_epoch----
recall@10:0.3650	 mrr@10:0.1581
recall@20:0.4944	 mrr@20:0.1671
best_result----
recall@10:0.3650	 mrr@10:0.1581	 epoch:21,21
recall@20:0.4945	 mrr@20:0.1671	 epoch:20,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-05-05 20:49:09.927808
	 train_loss : 21387.939
this_epoch----
recall@10:0.3649	 mrr@10:0.1582
recall@20:0.4945	 mrr@20:0.1672
best_result----
recall@10:0.3650	 mrr@10:0.1582	 epoch:21,22
recall@20:0.4945	 mrr@20:0.1672	 epoch:22,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-05-05 20:53:06.893576
	 train_loss : 21380.613
this_epoch----
recall@10:0.3645	 mrr@10:0.1582
recall@20:0.4945	 mrr@20:0.1672
best_result----
recall@10:0.3650	 mrr@10:0.1582	 epoch:21,22
recall@20:0.4945	 mrr@20:0.1672	 epoch:22,23
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-05-05 20:57:03.653459
	 train_loss : 21375.123
this_epoch----
recall@10:0.3648	 mrr@10:0.1582
recall@20:0.4946	 mrr@20:0.1672
best_result----
recall@10:0.3650	 mrr@10:0.1582	 epoch:21,24
recall@20:0.4946	 mrr@20:0.1672	 epoch:24,24
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-05-05 21:01:00.898161
	 train_loss : 21370.834
this_epoch----
recall@10:0.3650	 mrr@10:0.1583
recall@20:0.4947	 mrr@20:0.1673
best_result----
recall@10:0.3650	 mrr@10:0.1583	 epoch:21,25
recall@20:0.4947	 mrr@20:0.1673	 epoch:25,25
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-05-05 21:04:58.378549
	 train_loss : 21367.242
this_epoch----
recall@10:0.3647	 mrr@10:0.1583
recall@20:0.4946	 mrr@20:0.1672
best_result----
recall@10:0.3650	 mrr@10:0.1583	 epoch:21,25
recall@20:0.4947	 mrr@20:0.1673	 epoch:25,25
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-05-05 21:08:54.899040
	 train_loss : 21362.941
this_epoch----
recall@10:0.3647	 mrr@10:0.1582
recall@20:0.4948	 mrr@20:0.1672
best_result----
recall@10:0.3650	 mrr@10:0.1583	 epoch:21,25
recall@20:0.4948	 mrr@20:0.1673	 epoch:27,25
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-05-05 21:12:52.710233
	 train_loss : 21360.912
this_epoch----
recall@10:0.3648	 mrr@10:0.1583
recall@20:0.4945	 mrr@20:0.1673
best_result----
recall@10:0.3650	 mrr@10:0.1583	 epoch:21,25
recall@20:0.4948	 mrr@20:0.1673	 epoch:27,28
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-05-05 21:16:51.236385
	 train_loss : 21358.117
this_epoch----
recall@10:0.3650	 mrr@10:0.1582
recall@20:0.4947	 mrr@20:0.1672
best_result----
recall@10:0.3650	 mrr@10:0.1583	 epoch:21,25
recall@20:0.4948	 mrr@20:0.1673	 epoch:27,28
Done
