nohup: ignoring input
Namespace(batch_size=100, dataset='diginetica', emb_size=100, epoch=30, epsilon=0.85, evaluate_k=[10, 20], l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, patience=10, temp=0.1)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-04-08 13:04:27.573055
	 train_loss : 48854.977
this_epoch----
recall@10:0.1408	 mrr@10:0.0522
recall@20:0.2033	 mrr@20:0.0565
best_result----
recall@10:0.1408	 mrr@10:0.0522	 epoch:0,0
recall@20:0.2033	 mrr@20:0.0565	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-04-08 13:13:13.227057
	 train_loss : 35146.539
this_epoch----
recall@10:0.2542	 mrr@10:0.0993
recall@20:0.3633	 mrr@20:0.1069
best_result----
recall@10:0.2542	 mrr@10:0.0993	 epoch:1,1
recall@20:0.3633	 mrr@20:0.1069	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-04-08 13:24:32.550795
	 train_loss : 29810.350
this_epoch----
recall@10:0.2842	 mrr@10:0.1104
recall@20:0.4058	 mrr@20:0.1188
best_result----
recall@10:0.2842	 mrr@10:0.1104	 epoch:2,2
recall@20:0.4058	 mrr@20:0.1188	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-04-08 13:35:41.774877
	 train_loss : 27919.475
this_epoch----
recall@10:0.2947	 mrr@10:0.1176
recall@20:0.4180	 mrr@20:0.1261
best_result----
recall@10:0.2947	 mrr@10:0.1176	 epoch:3,3
recall@20:0.4180	 mrr@20:0.1261	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-04-08 13:46:48.768819
	 train_loss : 26809.898
this_epoch----
recall@10:0.3063	 mrr@10:0.1225
recall@20:0.4285	 mrr@20:0.1310
best_result----
recall@10:0.3063	 mrr@10:0.1225	 epoch:4,4
recall@20:0.4285	 mrr@20:0.1310	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-04-08 13:57:58.446894
	 train_loss : 25994.852
this_epoch----
recall@10:0.3065	 mrr@10:0.1240
recall@20:0.4295	 mrr@20:0.1325
best_result----
recall@10:0.3065	 mrr@10:0.1240	 epoch:5,5
recall@20:0.4295	 mrr@20:0.1325	 epoch:5,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-04-08 14:09:02.754198
	 train_loss : 25332.836
this_epoch----
recall@10:0.3081	 mrr@10:0.1238
recall@20:0.4320	 mrr@20:0.1324
best_result----
recall@10:0.3081	 mrr@10:0.1240	 epoch:6,5
recall@20:0.4320	 mrr@20:0.1325	 epoch:6,5
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-04-08 14:20:16.680722
	 train_loss : 24754.479
this_epoch----
recall@10:0.3111	 mrr@10:0.1260
recall@20:0.4341	 mrr@20:0.1345
best_result----
recall@10:0.3111	 mrr@10:0.1260	 epoch:7,7
recall@20:0.4341	 mrr@20:0.1345	 epoch:7,7
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-04-08 14:31:27.689614
	 train_loss : 24253.635
this_epoch----
recall@10:0.3071	 mrr@10:0.1236
recall@20:0.4325	 mrr@20:0.1323
best_result----
recall@10:0.3111	 mrr@10:0.1260	 epoch:7,7
recall@20:0.4341	 mrr@20:0.1345	 epoch:7,7
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-04-08 14:42:33.859105
	 train_loss : 23798.070
this_epoch----
recall@10:0.3038	 mrr@10:0.1220
recall@20:0.4285	 mrr@20:0.1306
best_result----
recall@10:0.3111	 mrr@10:0.1260	 epoch:7,7
recall@20:0.4341	 mrr@20:0.1345	 epoch:7,7
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-04-08 14:51:02.079981
	 train_loss : 20632.605
this_epoch----
recall@10:0.3298	 mrr@10:0.1371
recall@20:0.4530	 mrr@20:0.1457
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:10,10
recall@20:0.4530	 mrr@20:0.1457	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-04-08 14:59:01.503515
	 train_loss : 20039.158
this_epoch----
recall@10:0.3298	 mrr@10:0.1364
recall@20:0.4536	 mrr@20:0.1450
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-04-08 15:07:14.208657
	 train_loss : 19815.732
this_epoch----
recall@10:0.3290	 mrr@10:0.1357
recall@20:0.4509	 mrr@20:0.1442
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-04-08 15:15:27.182371
	 train_loss : 19645.639
this_epoch----
recall@10:0.3277	 mrr@10:0.1345
recall@20:0.4498	 mrr@20:0.1430
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-04-08 15:23:39.695321
	 train_loss : 19500.264
this_epoch----
recall@10:0.3265	 mrr@10:0.1346
recall@20:0.4486	 mrr@20:0.1430
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-04-08 15:31:51.648592
	 train_loss : 19368.598
this_epoch----
recall@10:0.3247	 mrr@10:0.1331
recall@20:0.4471	 mrr@20:0.1416
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-04-08 15:40:04.607052
	 train_loss : 19246.943
this_epoch----
recall@10:0.3239	 mrr@10:0.1328
recall@20:0.4444	 mrr@20:0.1412
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-04-08 15:48:17.510641
	 train_loss : 19133.561
this_epoch----
recall@10:0.3230	 mrr@10:0.1327
recall@20:0.4440	 mrr@20:0.1411
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-04-08 15:56:29.757766
	 train_loss : 19026.207
this_epoch----
recall@10:0.3220	 mrr@10:0.1315
recall@20:0.4424	 mrr@20:0.1398
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-04-08 16:04:43.608451
	 train_loss : 18921.088
this_epoch----
recall@10:0.3205	 mrr@10:0.1309
recall@20:0.4411	 mrr@20:0.1392
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-04-08 16:12:56.024982
	 train_loss : 18331.240
this_epoch----
recall@10:0.3207	 mrr@10:0.1313
recall@20:0.4410	 mrr@20:0.1396
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-04-08 16:21:08.571604
	 train_loss : 18292.328
this_epoch----
recall@10:0.3209	 mrr@10:0.1316
recall@20:0.4413	 mrr@20:0.1400
best_result----
recall@10:0.3298	 mrr@10:0.1371	 epoch:11,10
recall@20:0.4536	 mrr@20:0.1457	 epoch:11,10
Done
