nohup: ignoring input
Namespace(dataset='diginetica', emb_size=100, batch_size=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, temp=0.1, evaluate_k=[10, 20], epsilon=0.85, epoch=30, patience=10)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-05-05 21:23:58.700321
	 train_loss : 37238.383
this_epoch----
recall@10:0.3119	 mrr@10:0.1286
recall@20:0.4355	 mrr@20:0.1371
best_result----
recall@10:0.3119	 mrr@10:0.1286	 epoch:0,0
recall@20:0.4355	 mrr@20:0.1371	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-05-05 21:27:53.890822
	 train_loss : 28169.221
this_epoch----
recall@10:0.3259	 mrr@10:0.1354
recall@20:0.4562	 mrr@20:0.1444
best_result----
recall@10:0.3259	 mrr@10:0.1354	 epoch:1,1
recall@20:0.4562	 mrr@20:0.1444	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-05-05 21:31:52.551358
	 train_loss : 26843.107
this_epoch----
recall@10:0.3297	 mrr@10:0.1378
recall@20:0.4578	 mrr@20:0.1466
best_result----
recall@10:0.3297	 mrr@10:0.1378	 epoch:2,2
recall@20:0.4578	 mrr@20:0.1466	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-05-05 21:35:53.846765
	 train_loss : 26303.906
this_epoch----
recall@10:0.3318	 mrr@10:0.1380
recall@20:0.4619	 mrr@20:0.1470
best_result----
recall@10:0.3318	 mrr@10:0.1380	 epoch:3,3
recall@20:0.4619	 mrr@20:0.1470	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-05-05 21:39:50.121365
	 train_loss : 26004.986
this_epoch----
recall@10:0.3371	 mrr@10:0.1423
recall@20:0.4658	 mrr@20:0.1511
best_result----
recall@10:0.3371	 mrr@10:0.1423	 epoch:4,4
recall@20:0.4658	 mrr@20:0.1511	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-05-05 21:43:48.906399
	 train_loss : 25798.857
this_epoch----
recall@10:0.3364	 mrr@10:0.1423
recall@20:0.4658	 mrr@20:0.1512
best_result----
recall@10:0.3371	 mrr@10:0.1423	 epoch:4,5
recall@20:0.4658	 mrr@20:0.1512	 epoch:4,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-05-05 21:47:56.040479
	 train_loss : 25671.982
this_epoch----
recall@10:0.3387	 mrr@10:0.1436
recall@20:0.4645	 mrr@20:0.1522
best_result----
recall@10:0.3387	 mrr@10:0.1436	 epoch:6,6
recall@20:0.4658	 mrr@20:0.1522	 epoch:4,6
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-05-05 21:52:03.232934
	 train_loss : 25572.582
this_epoch----
recall@10:0.3386	 mrr@10:0.1425
recall@20:0.4700	 mrr@20:0.1515
best_result----
recall@10:0.3387	 mrr@10:0.1436	 epoch:6,6
recall@20:0.4700	 mrr@20:0.1522	 epoch:7,6
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-05-05 21:56:09.649152
	 train_loss : 25507.264
this_epoch----
recall@10:0.3389	 mrr@10:0.1432
recall@20:0.4684	 mrr@20:0.1521
best_result----
recall@10:0.3389	 mrr@10:0.1436	 epoch:8,6
recall@20:0.4700	 mrr@20:0.1522	 epoch:7,6
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-05-05 22:00:16.179687
	 train_loss : 25451.900
this_epoch----
recall@10:0.3420	 mrr@10:0.1432
recall@20:0.4695	 mrr@20:0.1520
best_result----
recall@10:0.3420	 mrr@10:0.1436	 epoch:9,6
recall@20:0.4700	 mrr@20:0.1522	 epoch:7,6
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-05-05 22:04:23.084263
	 train_loss : 22834.307
this_epoch----
recall@10:0.3619	 mrr@10:0.1551
recall@20:0.4901	 mrr@20:0.1639
best_result----
recall@10:0.3619	 mrr@10:0.1551	 epoch:10,10
recall@20:0.4901	 mrr@20:0.1639	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-05-05 22:08:29.981209
	 train_loss : 22326.031
this_epoch----
recall@10:0.3631	 mrr@10:0.1561
recall@20:0.4919	 mrr@20:0.1651
best_result----
recall@10:0.3631	 mrr@10:0.1561	 epoch:11,11
recall@20:0.4919	 mrr@20:0.1651	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-05-05 22:12:36.398806
	 train_loss : 22169.676
this_epoch----
recall@10:0.3633	 mrr@10:0.1567
recall@20:0.4933	 mrr@20:0.1657
best_result----
recall@10:0.3633	 mrr@10:0.1567	 epoch:12,12
recall@20:0.4933	 mrr@20:0.1657	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-05-05 22:16:43.231110
	 train_loss : 22087.707
this_epoch----
recall@10:0.3637	 mrr@10:0.1564
recall@20:0.4930	 mrr@20:0.1654
best_result----
recall@10:0.3637	 mrr@10:0.1567	 epoch:13,12
recall@20:0.4933	 mrr@20:0.1657	 epoch:12,12
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-05-05 22:20:49.683991
	 train_loss : 22038.266
this_epoch----
recall@10:0.3645	 mrr@10:0.1570
recall@20:0.4930	 mrr@20:0.1659
best_result----
recall@10:0.3645	 mrr@10:0.1570	 epoch:14,14
recall@20:0.4933	 mrr@20:0.1659	 epoch:12,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-05-05 22:24:55.891793
	 train_loss : 22006.041
this_epoch----
recall@10:0.3636	 mrr@10:0.1568
recall@20:0.4938	 mrr@20:0.1658
best_result----
recall@10:0.3645	 mrr@10:0.1570	 epoch:14,14
recall@20:0.4938	 mrr@20:0.1659	 epoch:15,14
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-05-05 22:28:56.749811
	 train_loss : 21983.395
this_epoch----
recall@10:0.3648	 mrr@10:0.1577
recall@20:0.4937	 mrr@20:0.1666
best_result----
recall@10:0.3648	 mrr@10:0.1577	 epoch:16,16
recall@20:0.4938	 mrr@20:0.1666	 epoch:15,16
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-05-05 22:32:54.620050
	 train_loss : 21967.154
this_epoch----
recall@10:0.3635	 mrr@10:0.1575
recall@20:0.4939	 mrr@20:0.1666
best_result----
recall@10:0.3648	 mrr@10:0.1577	 epoch:16,16
recall@20:0.4939	 mrr@20:0.1666	 epoch:17,16
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-05-05 22:36:50.675252
	 train_loss : 21957.229
this_epoch----
recall@10:0.3638	 mrr@10:0.1575
recall@20:0.4929	 mrr@20:0.1665
best_result----
recall@10:0.3648	 mrr@10:0.1577	 epoch:16,16
recall@20:0.4939	 mrr@20:0.1666	 epoch:17,16
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-05-05 22:40:46.790942
	 train_loss : 21950.086
this_epoch----
recall@10:0.3642	 mrr@10:0.1571
recall@20:0.4940	 mrr@20:0.1661
best_result----
recall@10:0.3648	 mrr@10:0.1577	 epoch:16,16
recall@20:0.4940	 mrr@20:0.1666	 epoch:19,16
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-05-05 22:44:45.640683
	 train_loss : 21416.307
this_epoch----
recall@10:0.3642	 mrr@10:0.1577
recall@20:0.4941	 mrr@20:0.1667
best_result----
recall@10:0.3648	 mrr@10:0.1577	 epoch:16,16
recall@20:0.4941	 mrr@20:0.1667	 epoch:20,20
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-05-05 22:48:43.625389
	 train_loss : 21398.271
this_epoch----
recall@10:0.3643	 mrr@10:0.1577
recall@20:0.4939	 mrr@20:0.1667
best_result----
recall@10:0.3648	 mrr@10:0.1577	 epoch:16,21
recall@20:0.4941	 mrr@20:0.1667	 epoch:20,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-05-05 22:52:42.823127
	 train_loss : 21386.717
this_epoch----
recall@10:0.3644	 mrr@10:0.1579
recall@20:0.4940	 mrr@20:0.1669
best_result----
recall@10:0.3648	 mrr@10:0.1579	 epoch:16,22
recall@20:0.4941	 mrr@20:0.1669	 epoch:20,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-05-05 22:56:41.930213
	 train_loss : 21379.367
this_epoch----
recall@10:0.3644	 mrr@10:0.1581
recall@20:0.4941	 mrr@20:0.1671
best_result----
recall@10:0.3648	 mrr@10:0.1581	 epoch:16,23
recall@20:0.4941	 mrr@20:0.1671	 epoch:20,23
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-05-05 23:00:40.892458
	 train_loss : 21374.336
this_epoch----
recall@10:0.3641	 mrr@10:0.1581
recall@20:0.4943	 mrr@20:0.1671
best_result----
recall@10:0.3648	 mrr@10:0.1581	 epoch:16,23
recall@20:0.4943	 mrr@20:0.1671	 epoch:24,23
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-05-05 23:04:37.809966
	 train_loss : 21370.061
this_epoch----
recall@10:0.3643	 mrr@10:0.1581
recall@20:0.4940	 mrr@20:0.1671
best_result----
recall@10:0.3648	 mrr@10:0.1581	 epoch:16,23
recall@20:0.4943	 mrr@20:0.1671	 epoch:24,23
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-05-05 23:08:35.295193
	 train_loss : 21367.014
this_epoch----
recall@10:0.3645	 mrr@10:0.1582
recall@20:0.4943	 mrr@20:0.1672
best_result----
recall@10:0.3648	 mrr@10:0.1582	 epoch:16,26
recall@20:0.4943	 mrr@20:0.1672	 epoch:24,26
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-05-05 23:12:32.863283
	 train_loss : 21362.527
this_epoch----
recall@10:0.3644	 mrr@10:0.1583
recall@20:0.4940	 mrr@20:0.1673
best_result----
recall@10:0.3648	 mrr@10:0.1583	 epoch:16,27
recall@20:0.4943	 mrr@20:0.1673	 epoch:24,27
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-05-05 23:16:29.318523
	 train_loss : 21360.039
this_epoch----
recall@10:0.3645	 mrr@10:0.1582
recall@20:0.4939	 mrr@20:0.1672
best_result----
recall@10:0.3648	 mrr@10:0.1583	 epoch:16,27
recall@20:0.4943	 mrr@20:0.1673	 epoch:24,27
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-05-05 23:20:26.359683
	 train_loss : 21357.324
this_epoch----
recall@10:0.3646	 mrr@10:0.1582
recall@20:0.4938	 mrr@20:0.1672
best_result----
recall@10:0.3648	 mrr@10:0.1583	 epoch:16,27
recall@20:0.4943	 mrr@20:0.1673	 epoch:24,27
Done
