nohup: ignoring input
Namespace(dataset='diginetica', emb_size=100, batch_size=100, l2=1e-05, lr=0.001, lr_dc=0.1, lr_dc_step=10, n_heads=3, n_intentions=3, temp=0.1, evaluate_k=[10, 20], epsilon=0.85, epoch=30, patience=10)
--------------------------------------
epoch 0
lr: 0.001
start training... 2022-05-10 19:55:54.720832
	 train_loss : 36885.367
this_epoch----
recall@10:0.3166	 mrr@10:0.1338
recall@20:0.4427	 mrr@20:0.1424
best_result----
recall@10:0.3166	 mrr@10:0.1338	 epoch:0,0
recall@20:0.4427	 mrr@20:0.1424	 epoch:0,0
--------------------------------------
epoch 1
lr: 0.001
start training... 2022-05-10 19:59:44.875429
	 train_loss : 27504.461
this_epoch----
recall@10:0.3280	 mrr@10:0.1365
recall@20:0.4601	 mrr@20:0.1457
best_result----
recall@10:0.3280	 mrr@10:0.1365	 epoch:1,1
recall@20:0.4601	 mrr@20:0.1457	 epoch:1,1
--------------------------------------
epoch 2
lr: 0.001
start training... 2022-05-10 20:03:34.609971
	 train_loss : 26344.205
this_epoch----
recall@10:0.3364	 mrr@10:0.1412
recall@20:0.4643	 mrr@20:0.1500
best_result----
recall@10:0.3364	 mrr@10:0.1412	 epoch:2,2
recall@20:0.4643	 mrr@20:0.1500	 epoch:2,2
--------------------------------------
epoch 3
lr: 0.001
start training... 2022-05-10 20:07:24.502407
	 train_loss : 25816.936
this_epoch----
recall@10:0.3394	 mrr@10:0.1423
recall@20:0.4699	 mrr@20:0.1512
best_result----
recall@10:0.3394	 mrr@10:0.1423	 epoch:3,3
recall@20:0.4699	 mrr@20:0.1512	 epoch:3,3
--------------------------------------
epoch 4
lr: 0.001
start training... 2022-05-10 20:11:15.745658
	 train_loss : 25499.779
this_epoch----
recall@10:0.3397	 mrr@10:0.1431
recall@20:0.4699	 mrr@20:0.1520
best_result----
recall@10:0.3397	 mrr@10:0.1431	 epoch:4,4
recall@20:0.4699	 mrr@20:0.1520	 epoch:4,4
--------------------------------------
epoch 5
lr: 0.001
start training... 2022-05-10 20:15:08.066859
	 train_loss : 25308.342
this_epoch----
recall@10:0.3397	 mrr@10:0.1443
recall@20:0.4713	 mrr@20:0.1534
best_result----
recall@10:0.3397	 mrr@10:0.1443	 epoch:4,5
recall@20:0.4713	 mrr@20:0.1534	 epoch:5,5
--------------------------------------
epoch 6
lr: 0.001
start training... 2022-05-10 20:18:59.154513
	 train_loss : 25166.850
this_epoch----
recall@10:0.3421	 mrr@10:0.1437
recall@20:0.4729	 mrr@20:0.1527
best_result----
recall@10:0.3421	 mrr@10:0.1443	 epoch:6,5
recall@20:0.4729	 mrr@20:0.1534	 epoch:6,5
--------------------------------------
epoch 7
lr: 0.001
start training... 2022-05-10 20:22:49.623089
	 train_loss : 25067.217
this_epoch----
recall@10:0.3416	 mrr@10:0.1436
recall@20:0.4722	 mrr@20:0.1526
best_result----
recall@10:0.3421	 mrr@10:0.1443	 epoch:6,5
recall@20:0.4729	 mrr@20:0.1534	 epoch:6,5
--------------------------------------
epoch 8
lr: 0.001
start training... 2022-05-10 20:26:39.890837
	 train_loss : 24994.189
this_epoch----
recall@10:0.3410	 mrr@10:0.1440
recall@20:0.4735	 mrr@20:0.1531
best_result----
recall@10:0.3421	 mrr@10:0.1443	 epoch:6,5
recall@20:0.4735	 mrr@20:0.1534	 epoch:8,5
--------------------------------------
epoch 9
lr: 0.001
start training... 2022-05-10 20:30:27.953038
	 train_loss : 24937.080
this_epoch----
recall@10:0.3455	 mrr@10:0.1454
recall@20:0.4757	 mrr@20:0.1544
best_result----
recall@10:0.3455	 mrr@10:0.1454	 epoch:9,9
recall@20:0.4757	 mrr@20:0.1544	 epoch:9,9
--------------------------------------
epoch 10
lr: 0.0001
start training... 2022-05-10 20:34:15.136745
	 train_loss : 22392.732
this_epoch----
recall@10:0.3655	 mrr@10:0.1565
recall@20:0.4940	 mrr@20:0.1654
best_result----
recall@10:0.3655	 mrr@10:0.1565	 epoch:10,10
recall@20:0.4940	 mrr@20:0.1654	 epoch:10,10
--------------------------------------
epoch 11
lr: 0.0001
start training... 2022-05-10 20:38:02.459850
	 train_loss : 21907.396
this_epoch----
recall@10:0.3677	 mrr@10:0.1577
recall@20:0.4972	 mrr@20:0.1666
best_result----
recall@10:0.3677	 mrr@10:0.1577	 epoch:11,11
recall@20:0.4972	 mrr@20:0.1666	 epoch:11,11
--------------------------------------
epoch 12
lr: 0.0001
start training... 2022-05-10 20:42:02.747971
	 train_loss : 21758.998
this_epoch----
recall@10:0.3676	 mrr@10:0.1580
recall@20:0.4988	 mrr@20:0.1671
best_result----
recall@10:0.3677	 mrr@10:0.1580	 epoch:11,12
recall@20:0.4988	 mrr@20:0.1671	 epoch:12,12
--------------------------------------
epoch 13
lr: 0.0001
start training... 2022-05-10 20:58:23.115528
	 train_loss : 21681.506
this_epoch----
recall@10:0.3669	 mrr@10:0.1585
recall@20:0.4989	 mrr@20:0.1676
best_result----
recall@10:0.3677	 mrr@10:0.1585	 epoch:11,13
recall@20:0.4989	 mrr@20:0.1676	 epoch:13,13
--------------------------------------
epoch 14
lr: 0.0001
start training... 2022-05-10 21:14:58.841178
	 train_loss : 21636.154
this_epoch----
recall@10:0.3679	 mrr@10:0.1589
recall@20:0.4986	 mrr@20:0.1679
best_result----
recall@10:0.3679	 mrr@10:0.1589	 epoch:14,14
recall@20:0.4989	 mrr@20:0.1679	 epoch:13,14
--------------------------------------
epoch 15
lr: 0.0001
start training... 2022-05-10 21:31:07.283641
	 train_loss : 21607.867
this_epoch----
recall@10:0.3676	 mrr@10:0.1584
recall@20:0.4982	 mrr@20:0.1675
best_result----
recall@10:0.3679	 mrr@10:0.1589	 epoch:14,14
recall@20:0.4989	 mrr@20:0.1679	 epoch:13,14
--------------------------------------
epoch 16
lr: 0.0001
start training... 2022-05-10 21:46:36.150261
	 train_loss : 21587.697
this_epoch----
recall@10:0.3682	 mrr@10:0.1586
recall@20:0.4993	 mrr@20:0.1677
best_result----
recall@10:0.3682	 mrr@10:0.1589	 epoch:16,14
recall@20:0.4993	 mrr@20:0.1679	 epoch:16,14
--------------------------------------
epoch 17
lr: 0.0001
start training... 2022-05-10 22:02:19.943486
	 train_loss : 21576.211
this_epoch----
recall@10:0.3670	 mrr@10:0.1589
recall@20:0.4983	 mrr@20:0.1680
best_result----
recall@10:0.3682	 mrr@10:0.1589	 epoch:16,17
recall@20:0.4993	 mrr@20:0.1680	 epoch:16,17
--------------------------------------
epoch 18
lr: 0.0001
start training... 2022-05-10 22:18:14.780954
	 train_loss : 21566.400
this_epoch----
recall@10:0.3675	 mrr@10:0.1587
recall@20:0.4993	 mrr@20:0.1679
best_result----
recall@10:0.3682	 mrr@10:0.1589	 epoch:16,17
recall@20:0.4993	 mrr@20:0.1680	 epoch:18,17
--------------------------------------
epoch 19
lr: 0.0001
start training... 2022-05-10 22:33:55.592445
	 train_loss : 21563.303
this_epoch----
recall@10:0.3668	 mrr@10:0.1590
recall@20:0.4974	 mrr@20:0.1680
best_result----
recall@10:0.3682	 mrr@10:0.1590	 epoch:16,19
recall@20:0.4993	 mrr@20:0.1680	 epoch:18,19
--------------------------------------
epoch 20
lr: 1e-05
start training... 2022-05-10 22:49:21.831113
	 train_loss : 21053.084
this_epoch----
recall@10:0.3668	 mrr@10:0.1589
recall@20:0.4980	 mrr@20:0.1680
best_result----
recall@10:0.3682	 mrr@10:0.1590	 epoch:16,19
recall@20:0.4993	 mrr@20:0.1680	 epoch:18,19
--------------------------------------
epoch 21
lr: 1e-05
start training... 2022-05-10 23:05:01.141769
	 train_loss : 21036.082
this_epoch----
recall@10:0.3673	 mrr@10:0.1591
recall@20:0.4985	 mrr@20:0.1682
best_result----
recall@10:0.3682	 mrr@10:0.1591	 epoch:16,21
recall@20:0.4993	 mrr@20:0.1682	 epoch:18,21
--------------------------------------
epoch 22
lr: 1e-05
start training... 2022-05-10 23:20:52.844723
	 train_loss : 21026.320
this_epoch----
recall@10:0.3674	 mrr@10:0.1594
recall@20:0.4985	 mrr@20:0.1685
best_result----
recall@10:0.3682	 mrr@10:0.1594	 epoch:16,22
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
--------------------------------------
epoch 23
lr: 1e-05
start training... 2022-05-10 23:36:21.173307
	 train_loss : 21020.604
this_epoch----
recall@10:0.3678	 mrr@10:0.1594
recall@20:0.4986	 mrr@20:0.1684
best_result----
recall@10:0.3682	 mrr@10:0.1594	 epoch:16,23
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
--------------------------------------
epoch 24
lr: 1e-05
start training... 2022-05-10 23:51:48.654396
	 train_loss : 21015.627
this_epoch----
recall@10:0.3683	 mrr@10:0.1594
recall@20:0.4989	 mrr@20:0.1684
best_result----
recall@10:0.3683	 mrr@10:0.1594	 epoch:24,24
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
--------------------------------------
epoch 25
lr: 1e-05
start training... 2022-05-11 00:07:31.119210
	 train_loss : 21011.596
this_epoch----
recall@10:0.3683	 mrr@10:0.1593
recall@20:0.4989	 mrr@20:0.1684
best_result----
recall@10:0.3683	 mrr@10:0.1594	 epoch:25,24
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
--------------------------------------
epoch 26
lr: 1e-05
start training... 2022-05-11 00:23:17.615253
	 train_loss : 21008.996
this_epoch----
recall@10:0.3684	 mrr@10:0.1593
recall@20:0.4989	 mrr@20:0.1683
best_result----
recall@10:0.3684	 mrr@10:0.1594	 epoch:26,24
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
--------------------------------------
epoch 27
lr: 1e-05
start training... 2022-05-11 00:39:05.970972
	 train_loss : 21006.760
this_epoch----
recall@10:0.3681	 mrr@10:0.1592
recall@20:0.4992	 mrr@20:0.1683
best_result----
recall@10:0.3684	 mrr@10:0.1594	 epoch:26,24
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
--------------------------------------
epoch 28
lr: 1e-05
start training... 2022-05-11 00:54:57.700801
	 train_loss : 21004.229
this_epoch----
recall@10:0.3681	 mrr@10:0.1592
recall@20:0.4990	 mrr@20:0.1683
best_result----
recall@10:0.3684	 mrr@10:0.1594	 epoch:26,24
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
--------------------------------------
epoch 29
lr: 1e-05
start training... 2022-05-11 01:10:58.315502
	 train_loss : 21002.473
this_epoch----
recall@10:0.3684	 mrr@10:0.1593
recall@20:0.4991	 mrr@20:0.1684
best_result----
recall@10:0.3684	 mrr@10:0.1594	 epoch:29,24
recall@20:0.4993	 mrr@20:0.1685	 epoch:18,22
Done
